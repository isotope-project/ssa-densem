%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0

\documentclass[acmsmall,screen,review]{acmart}

\usepackage{syntax}
\renewcommand{\syntleft}{\normalfont\itshape}
\renewcommand{\syntright}{\normalfont\itshape}

\usepackage{prftree}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{fancyvrb}
\usepackage{enumitem}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
%    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\newcounter{todos}
\newcommand{\TODO}[1]{{
  \stepcounter{todos}
  \begin{center}\large{\textcolor{red}{\textbf{TODO \arabic{todos}:} #1}}\end{center}
}}
\newcommand{\sorry}{\textcolor{red}{\textbf{sorry}}}

\newcommand{\todo}[1]{\stepcounter{todos} \textcolor{red}{TODO \arabic{todos}: #1}}

% Math fonts
\newcommand{\mc}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\mb}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\ms}[1]{\ensuremath{\mathsf{#1}}}

% Math
\newcommand{\nats}{\mathbb{N}}

% Syntax atoms
\newcommand{\lbl}[1]{{`#1}}
\newcommand{\lto}{:}
\newcommand{\linl}[1]{\ms{inl}\;{#1}}
\newcommand{\linr}[1]{\ms{inr}\;{#1}}
\newcommand{\labort}[1]{\ms{abort}\;{#1}}

% Syntax
\newcommand{\letexpr}[3]{\ensuremath{\ms{let}\;#1 = #2;\;#3}}
\newcommand{\caseexpr}[5]{\ms{case}\;#1\;\{\linl{#2} \lto #3, \linr{#4} \lto #5\}}
\newcommand{\letstmt}[3]{\ensuremath{\ms{let}\;#1 = #2; #3}}
\newcommand{\brb}[2]{\ms{br}\;#1\;#2}
\newcommand{\ite}[3]{\ms{if}\;#1\;\{#2\}\;\ms{else}\;\{#3\}}
\newcommand{\casestmt}[5]{\ms{case}\;#1\;\{\linl{#2} \lto #3, \linr{#4} \lto #5\}}
\newcommand{\where}[2]{#1\;\ms{where}\;#2}
\newcommand{\wbranch}[3]{#1(#2) \lto \{#3\}}
\newcommand{\cfgsubst}[1]{\ms{cfgs}\;\{#1\}}
\newcommand{\wseq}[2]{{#1} \mathbin{{;}{;}} {#2}}

% Judgements
\newcommand{\cwk}[2]{#1 \mapsto #2}
\newcommand{\lwk}[2]{#1 \rightsquigarrow #2}
\newcommand{\thyp}[3]{#1 : {#2}^{#3}}
\newcommand{\bhyp}[2]{#1 : #2}
\newcommand{\lhyp}[2]{#1(#2)}
\newcommand{\rle}[1]{{\scriptsize\textsf{#1}}}
\newcommand{\hasty}[4]{#1 \vdash_{#2} #3: {#4}}
\newcommand{\haslb}[3]{#1 \vdash #2 \rhd #3}
\newcommand{\isop}[4]{#1 \in \mc{I}_{#4}(#2, #3)}
\newcommand{\issubst}[3]{#1: #2 \mapsto #3}
\newcommand{\lbsubst}[4]{#1 \vdash #2: #3 \rightsquigarrow #4}
\newcommand{\teqv}{\approx}
\newcommand{\tmeq}[5]{#1 \vdash_{#2} #3 \teqv #4 : {#5}}
\newcommand{\lbeq}[4]{#1 \vdash #2 \teqv #3 : {#4}}
\newcommand{\tmseq}[4]{\issubst{#1 \teqv #2}{#3}{#4}}
\newcommand{\lbseq}[5]{\lbsubst{#1 \teqv #2}{#3}{#4}{#5}}
\newcommand{\brle}[1]{{\scriptsize\textsf{#1}}}

% Denotational semantics
\newcommand{\dnt}[1]{\llbracket{#1}\rrbracket}
\newcommand{\ednt}[1]{\left\llbracket{#1}\right\rrbracket}
\newcommand{\tmor}[1]{{!}_{#1}}
\newcommand{\dmor}[1]{{\Delta}_{#1}}

% Composition
\newcommand{\invar}{\square}

% Weak memory
\newcommand{\bufloc}[1]{\overline{#1}}

% Branding
\newcommand{\isotopessa}{\(\lambda_{\ms{SSA}}\)}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
% \acmJournal{JACM}
% \acmVolume{37}
% \acmNumber{4}
% \acmArticle{111}
% \acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

\begin{document}

\title{The Denotational Semantics of SSA}

\author{Jad Ghalayini}
\email{jeg74@cl.cam.ac.uk}
\orcid{0000-0002-6905-1303}

\author{Neel Krishnaswami}
\email{nk480@cl.cam.ac.uk}
\orcid{0000-0003-2838-5865}

\begin{abstract}
  ...
\end{abstract}

\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10003752.10010124.10010131.10010133</concept_id>
  <concept_desc>Theory of computation~Denotational semantics</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010131.10010137</concept_id>
  <concept_desc>Theory of computation~Categorical semantics</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10003790.10011740</concept_id>
  <concept_desc>Theory of computation~Type theory</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Denotational semantics}
\ccsdesc[500]{Theory of computation~Categorical semantics}
\ccsdesc[500]{Theory of computation~Type theory}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{SSA, Categorical Semantics, Elgot Structure, Effectful Category}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\maketitle

\section{Introduction}

Static single assignment form, or SSA form, has been the dominant
compiler intermediate representation since its introduction by
\citet{ssa-intro} in the later 1980s. Every major compiler -- GCC, Clang,
MLIR, Cranelift -- uses this representation, because it makes many
optimizations much easier to do than traditional 3-address code IRs.

The key i behind SSA is to adapt an idea from functional
programming: namely, every variable is defined only once. This means
that substitution is unconditionally valid, without first requiring a
dataflow analysis to compute where definitions reach. Unlike in
functional programming, though, scoping of definitions in SSA is
traditionally not lexical. Instead, scoping is determined by
\emph{dominance}: every variable occurence must be dominated by a
single assignment in the control flow graph.

The semantics of SSA has traditionally been handled quite informally,
because conceptually, it is a simple first-order imperative
programming language. As a result, whether a rewrite is sound or
not is usually obvious, without having to do a complex correctness
argument.

Unfortunately, computers are no longer as simple as they were in the
late 1980s. Modern computers are typically multicore, and feature many
levels of caching, and as a result the semantics of memory is no
longer correctly modelled as a big array of bytes. Finding good
semantics for modern weak memory systems remains an ongoing challenge.

As a result, it is not correct to justify compiler optimizations in
terms of a simple imperative model, and it is an open question which
equations should hold of an SSA program. This is a particularly
fraught question, because it is also unclear which equations weak
memory models should satisfy.

What we would like to know is which equations any SSA representation
should satisfy. This would let us establish a contract between
compiler writers and hardware designers. The compiler writers could
rely upon the equational theory of SSA when justifying optimizations,
without needing to know all the details of the memory model at all
times.  Conversely, memory models could be validated by seeing if they
satisfy the equations of SSA, without needing to study every possible
compiler optimization.

Concretely, our contributions are as follows: 

\begin{itemize}
\item First, we give a type-theoretic presentation of SSA, with both typing rules and an equational
  theory for well-typed terms. We also prove the correctness of suitable substitution properties for
  this calculus. 
  
\item Next, we give a categorical semantics for this type theory, in terms of distributive Elgot
  categories. We show that any denotational model with this categorical structure is also a model of
  SSA. This shows that all of the equations we give are sound with respect to the categorical
  structure. 

\item We also show that syntax quotiented by the equational theory yields the initial distributive
  Elgot category. This establishes that our set of syntactic equations is complete, and that there
  are no equations which the denotational semantics validates, but which cannot be proved
  syntactically. 

\item We show that this denotational axiomatization is useful in practice, by giving a variety of
  concrete models, including a model of TSO weak memory based on~\cite{sparky}. This demonstrates
  that it is possible to give realistic weak memory models which do not disturb the structure of SSA
  in fundamental ways.

\item Finally, we have substantially mechanized our proofs using the Lean 4 proof assistant. We have
  mechanized proofs of substitution for our type theory, as well as proofs that the syntax forms the
  initial model, and that the SPARC TSO semantics forms a valid model of SSA. The denotational
  semantics and its proof of the soundness of substitution are done on paper. 

\end{itemize}

\section{Static Single Assignment Form}

In this section, we will describe SSA form and the isomorphism between the standard $\phi$-node
based presentation and the more functional basic-blocks with arguments format. We will then discuss
standard dominance-based scoping, and how this can be recast as lexical scoping to make it more
amenable to standard type-theoretic treatment. We will then generalize this format to allow
branching to arbitrary code, rather than only labels, to obtain \textit{A-normal form}, or ANF
\cite{flanagan-93-anf}, analogously to~\citet{chakravarty-functional-ssa-2003}; a straightforward
argument shows that this adds no expressive power. Finally, to allow for substitution, we will
further generalize our syntax to allow for arbitrary expression nesting, as well as let-expressions,
to obtain \textit{type-theoretic SSA}, or \isotopessa, which will be the subject of the rest of this
paper.

As a running example, consider the simple imperative program to compute $10!$ given in
Figure~\ref{fig:fact-program}. 

Operating directly on an imperative language can be challenging, since having a uniform
representation of code friendly to mechanized optimization and analysis is often in tension with
features designed to improve readability and programmer productivity, such as syntax sugar. 


\TODO{3-address code was one of the first IRs; cite Frances Allen? Perhaps also cite
\cite{allen-70-cfa} for dominance lore?}

We might therefore normalize our code into \textit{3-address code}, as in
Figure~\ref{fig:fact-3addr}, by doing the following:
\begin{itemize}
  \item Converting structured control flow in terms of (e.g.) \ms{while} to unstructured jumps
  between the basic blocks \ms{start} (the entry block), \ms{loop}, and \ms{body}, which now have
  explicit labels. 
  \item Replacing subexpressions like $i + 1$ in $a * (i + 1)$ with let-bindings, so that every
  expression in our program is atomic. 
\end{itemize}

\begin{figure}
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{let\;mut}\;i = 1; \\
      & \ms{let\;mut}\;a = 1; \\
      & \ms{while}\;i_0 < n\;\{ \\
      & \quad a = a * (i + 1) \\
      & \quad i = i + 1; \\
      & \} \\
      & \ms{ret}\;a \\
    \end{align*}
    \caption{As an imperative program}
    \label{fig:fact-imp}
  \end{subfigure}%
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      \ms{start}:\quad  & \ms{let}\;n = 10; \\
                        & \ms{let\;mut}\;i = 1; \\
                        & \ms{let\;mut}\;a = 1; \\
                        & \ms{br}\;\ms{loop} \\
      \ms{loop}: \quad  & \ms{if}\;i < n\;
                          \{\;\ms{br}\;\ms{body}\;\}\;
                          \ms{else}\;\{\;\ms{ret}\;a\;\} \\
      \ms{body}: \quad  & \ms{let}\;t = i + 1; \\
                        & a = a * t; \\
                        & i = i + 1; \\
                        & \ms{br}\;\ms{loop}
    \end{align*}
    \caption{As 3-address code}
    \label{fig:fact-3addr}
  \end{subfigure}
  \caption{
    A simple, slightly suboptimal program to compute $10!$ via multiplication in a loop, represented
    as typical imperative code and in 3-address code.
  }
  \Description{}
  \label{fig:fact-program}
\end{figure}

\TODO{better segue; see below}

Unfortunately, many optimizations are still quite difficult to express in this format, since a
variable's value may have been set by many different definitions throughout the execution of the
program. To improve our ability to reason about programs, we introduce the \textit{static-single
assignment} restriction, which says that every variable must be defined at exactly one point in the
program. We can intuitively represent this as every variable being given by an immutable
\ms{let}-binding.

\TODO{a bit more SSA history; \citet{ssa-intro} again; also look at \citet{ssa-original}}

\todo{Explain why SSA is useful -- i.e., say substitution, even though it is not totally true\ldots}

It is difficult to express programs with loops in this format, since the value of a
variable may change on each iteration of the loop. The classical solution to this issue is to
introduce \textit{$\phi$-nodes}, which evaluate to a different value depending on which block we
\textit{previously} came from. For example, in basic block \ms{loop} in
Figure~\ref{fig:fact-ssa}, $i_0$ evaluates to 1 if we came from \ms{start}, and to $i_1$ if we
came from \ms{body}. Similarly, $a_0$ evaluates to 1 if we came from \ms{start}, and to $a_1$ if we
came from \ms{body}. This allows us to express the fact that the values of $i_0, a_0$ are
control-flow dependent while still maintaining the single-definition principle (as otherwise, we
would need a new definition for $i$ overriding the old one).

Note, however that $i_1, a_0$ are defined \textit{later} in the program than the
$\phi$-nodes $i_0, a_0$, which would normally be seen as using an undefined
value. We hence need to use the rather confusing scoping rule that the variables
in a branch of a $\phi$-node must be defined \textit{at the end of the source
basic block for that branch}, even if they are undefined when coming from other blocks. This in
general makes giving SSA an operational semantics quite confusing, and with much
time spent in compilers courses trying to build up the requisite intuition.

\begin{figure}
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      \ms{start}:\quad  & \ms{let}\;n = 10; \\
                        & \ms{let\;mut}\;i = 1; \\
                        & \ms{let\;mut}\;a = 1; \\
                        & \ms{br}\;\ms{loop} \\
      \ms{loop}: \quad  & \ms{if}\;i < n\;
                          \{\;\ms{br}\;\ms{body}\;\}\;
                          \ms{else}\;\{\;\ms{ret}\;a\;\} \\
      \ms{body}: \quad  & \ms{let}\;t = i + 1; \\
                        & a = a * t; \\
                        & i = i + 1; \\
                        & \ms{br}\;\ms{loop}
    \end{align*}
    \caption{3-address code}
  \end{subfigure}%
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      \ms{start}:\quad & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop} \\
      \ms{loop}: \quad  & \ms{let}\;i_0 = \phi(\ms{start}: 1, \ms{body}: i_1) \\
                        & \ms{let}\;a_0 = \phi(\ms{start}: 1, \ms{body}: a_1) \\
                        & \ms{if}\;i_0 < n\;
                          \{\;\ms{br}\;\ms{body}\;\}\;
                          \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      \ms{body}: \quad  & \ms{let}\;t = i_0 + 1 \\
                        & \ms{let}\;a_1 = a_0 * t \\
                        & \ms{let}\;i_1 = i_0 + 1 \\
                        & \ms{br}\;\ms{loop}
    \end{align*}
    \caption{Converted to SSA form}
    \label{fig:fact-ssa}
  \end{subfigure}
  \todo{add diagram showing correspondence between $\phi$-nodes and mutable bindings?}
  \caption{
    Conversion of three address code for the program in Figure~\ref{fig:fact-program} to SSA 
    form, requring the insertion of $\phi$-nodes for $i$ and $a$ due to control-flow dependent
    updates. Note how SSA-form can be viewed as ``three address code in which all 
    \ms{let}-bindings are immutable.''
  }
  \Description{}
\end{figure}

One solution to this issue is to transition to an isomorphic syntax called basic blocks with
arguments (BBA), as illustrated in Figure \ref{fig:fact-bba}. In this approach, each $\phi$-node,
which lacks side effects and whose scope depends solely on the originating basic blocks rather than
its position within its own block, can be moved to the top of the block. This reorganization allows
us to treat each $\phi$-node as equivalent to an argument for the basic block, with the
corresponding values passed at the jump site. Conversely, converting a program from BBA format back
to standard SSA form with $\phi$-nodes is straightforward: introduce a $\phi$-node for each argument
of a basic block, and then, for each branch corresponding to the $\phi$-node, add an argument to the
jump instruction from the appropriate source block. 

\begin{figure}
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \begin{align*}
      \ms{start}:\quad  & \ms{let}\;n = 10; \\
                        & \ms{br}\;\ms{loop} \\
      \ms{loop}: \quad  & \begingroup \color{red}
                          \ms{let}\;i_0 = \phi(\ms{start}: 1, \ms{body}: i_1) 
                          \endgroup \\
                        & \begingroup \color{blue}
                          \ms{let}\;a_0 = \phi(\ms{start}: 1, \ms{body}: a_1) 
                          \endgroup \\
                        & \ms{if}\;i_0 < n\;\{\;\ms{br}\;\ms{body}\;\} \\
                        & \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      \ms{body}: \quad  & \ms{let}\;t = i_0 + 1 \\
                        & \ms{let}\;a_1 = a_0 * t \\
                        & \ms{let}\;i_1 = i_0 + 1 \\
                        & \ms{br}\;\ms{loop}
    \end{align*}
    \caption{With $\phi$-nodes}
  \end{subfigure}%
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \begin{align*}
      \ms{start}:\quad            & \ms{let}\;n = 10; \\
                                  & \ms{br}\;\ms{loop}(\textcolor{red}{1}, \textcolor{blue}{1}) \\
      \ms{loop}(\textcolor{red}{i_0}, \textcolor{blue}{a_0}): \quad  
                                  & \ms{if}\;i_0 < n\; \{\;\ms{br}\;\ms{body}\;\} \\
                                  & \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      \ms{body}: \quad            & \ms{let}\;t = i_0 + 1 \\
                                  & \ms{let}\;a_1 = a_0 * t \\
                                  & \ms{let}\;i_1 = i_0 + 1 \\
                                  & \ms{br}\;\ms{loop}(\textcolor{red}{i_1}, \textcolor{blue}{a_1}) 
                                  \\ \\
    \end{align*}
    \caption{Basic-blocks with arguments}
    \label{fig:fact-bba}
  \end{subfigure}

  \TODO{Add arrows with \texttt{tikzmark}?}
  
  \caption{
    The program in Figure \ref{fig:fact-program} written in standard SSA (using $\phi$ nodes),
    like in LLVM \cite{llvm}, and in basic-blocks with arguments SSA, like in MLIR \cite{mlir} and
    Cranelift \cite{cranelift}. The arguments $i_0, a_0$ corresponding to the $\phi$-nodes $i_0,
    a_0$ are colored in \textcolor{red}{red} and \textcolor{blue}{blue}, respectively.
  }

  \Description{}
\end{figure}

An important insight provided by the BBA format, as discussed in \citet{appel-ssa}, is that a
program in SSA form may be interpreted as a collection of tail-recursive functions, where each
basic-block and branch correspond to a function and tail call respectively. This interpretation
offers a natural framework for defining the semantics of SSA and reasoning about optimizations.
However, there is a subtle difference between the scoping rules in this format and the actual
scoping used in traditional SSA, which requires careful consideration.

\TODO{Cite \citet{kelsey-95-cps} in paragraph above?}

In particular, while functional languages typically rely on \textit{lexical scoping}, where the
scope of a variable is determined by its position within the code's nested structure, SSA form
introduces a different scoping mechanism based on dominance. In SSA, a variable is considered to be
in scope at a specific point $P$ if and only if all execution paths from the program's entry point
to that point pass through the variable's unique definition $D$. In this case, we say that $P$ is
\textit{strictly dominated} by $D$.

When considering basic blocks, this translates to a variable being visible within the block $D$
where it is defined, starting from the point of its definition, and continuing to be visible in all
subsequent blocks $P$ strictly dominated by $D$ in the control-flow graph. For example, in
Figure~\ref{fig:fact-bba},
\begin{itemize}
  \item \ms{start} strictly dominates \ms{loop} and \ms{body}; so, for example, the variable $n$
  defined in \ms{start} is visible in \ms{loop}
  \item \ms{loop} strictly dominates \ms{body}, so the parameterts $i_0, a_0$ to \ms{loop} are
  visible, rather than needing to be passed in as parameters themselves as well
  \item \ms{body} does \textit{not} strictly dominate \ms{loop}, since there is trivially a path
  from \ms{start} to \ms{loop} which does not go through \ms{body}
\end{itemize}

In general, the relation ``$A$ strictly dominates $B$'' intersected with the relation ``$A$ jumps
directly to $B$'' (i.e. ``$A$ is a \textit{direct predecessor} of $B$'') forms a tree, called the
\textit{dominance tree} of the control-flow graph. This tree can be computed in nearly linear time
in the size of the CFG \cite{ssa-intro}. If we topologically sort the basic blocks in a CFG by the
corresponding partial order on blocks, we can insert brackets according to the dominance tree such
that a variable is in lexical scope if and only if it is in scope under dominance-based scoping, as
shown in Figure~\ref{fig:dominance-to-lexical}. This is a simple transformation, and it is easy to
see that it forms an isomorphism, as standard SSA can be recovered by simply removing the inserted
``\ms{where}-blocks."

\begin{figure}
  \centering
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      \ms{start}:\quad            & \ms{let}\;n = 10; \\
                                  & \ms{br}\;\ms{loop}(1, 1) \\
      \ms{loop}(i_0, a_0): \quad  & \ms{if}\;i_0 < n\; \{\;\ms{br}\;\ms{body}\;\} \\
                                  & \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      \ms{body}: \quad            & \ms{let}\;t = i_0 + 1 \\
                                  & \ms{let}\;a_1 = a_0 * t \\
                                  & \ms{let}\;i_1 = i_0 + 1 \\
                                  & \ms{br}\;\ms{loop}(i_1, a_1) \\ \\ \\ \\ 
    \end{align*}
    \caption{Dominance-based scoping}
  \end{subfigure}%
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{ \\
      & \quad \ms{if}\;i_0 < n\;\{\;\ms{br}\;\ms{body}\;\} \\
      & \quad \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      & \quad \ms{where}\;\ms{body}: \{\\ 
      & \qquad \ms{let}\;t = i_0 + 1 \\
      & \qquad \ms{let}\;a_1 = a_0 * t \\
      & \qquad \ms{let}\;i_1 = i_0 + 1 \\
      & \qquad \ms{br}\;\ms{loop}(i_1, a_1) \\
      & \quad \} \\
      & \}
    \end{align*}
    \caption{Lexical scoping}
  \end{subfigure}
  \caption{Conversion of an SSA program from dominance-based scoping to explicit lexical scoping}
  \Description{}
  \label{fig:dominance-to-lexical}
\end{figure}

\TODO{rework below:}

Lexical scoping allows us to apply many of the techniques developed in theoretical computer science
and functional programming for reasoning about and developing optimizations and analysis passes. In
particular, the result of our conversion to lexical scoping looks a lot like the correspondence
between CPS and SSA described in \citet{kelsey-95-cps}. In particular, we can now begin to develop
an \textit{equational theory} for SSA programs to reason about complex rewriting operations in a
compositional way. In particular, we'd like to be able to reason about:
\begin{itemize}
  \item \textit{Control-flow rewrites}, such as jump-threading or fusing two identical branches of
  an \ms{if}-statement
  \item \textit{Algebraic rewrites}, such as simplifying arithmetic expressions
  \item Combinations of the two, such as rewriting $\ms{if}\;x > 0\;\ms{then}\;1 - x\;\ms{else}\;1 +
  x$ to $1 + \ms{abs}(x)$.
\end{itemize}

We can work towards making these easier to express by generalizing our syntax to allow the branches
of if-statements to contain arbitrary code, rather than just unconditional branches, as in
Figure~\ref{fig:bba-to-anf}. This clearly adds no additional expressive power, since:
\begin{itemize}
  \item This syntax clearly generalizes the previous syntax, so no conversion into it is necessary
  \item To revert back to the less general syntax, one must simply introduce new anonymous basic
  blocks for each branch of the if-statement, likeso:
  \begin{equation}
    \ms{if}\;e\;\{s\}\;\ms{else}\;\{t\}
    \to (\ms{if}\;e\;\{\ms{br}\;\ell_\top\}\;\ms{else}\;\{\ms{br}\;\ell_\bot\})\;
        \ms{where}\;\ell_\top: \{s\},\;\ell_\bot: \{t\}
  \end{equation}
\end{itemize}

What we end up with is something which looks a lot like
\textit{administrative normal form} (ANF), with our transformation analogous to that described in
\citet{chakravarty-functional-ssa-2003}. The key difference is that, in our format (which is
strictly first order), we require an explicit \ms{ret} instruction (rather than adopting an expression-oriented language), and write ``$\ms{let\;rec}\;f(x) = e; t$" as ``$t\;\ms{where}\;f(x) : \{e\}$."

\begin{figure}
  \centering
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{ \\
      & \quad \ms{if}\;i_0 < n\;\{\;\ms{br}\;\ms{body}\;\} \\
      & \quad \ms{else}\;\{\;\ms{ret}\;a_0\;\} \\
      & \quad \ms{where}\;\ms{body}: \{\\ 
      & \qquad \ms{let}\;t = i_0 + 1 \\
      & \qquad \ms{let}\;a_1 = a_0 * t \\
      & \qquad \ms{let}\;i_1 = i_0 + 1 \\
      & \qquad \ms{br}\;\ms{loop}(i_1, a_1) \\
      & \quad \} \\
      & \}
    \end{align*}
  \end{subfigure}%
  \begin{subfigure}[t]{.5\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
      & \quad \ms{if}\;i_0 < n\;\{ \\
      & \qquad \ms{let}\;t = i_0 + 1 \\
      & \qquad \ms{let}\;a_1 = a_0 * t \\
      & \qquad \ms{let}\;i_1 = i_0 + 1 \\
      & \qquad \ms{br}\;\ms{loop}(i_1, a_1) \\
      & \quad \}\;\ms{else}\;\{ \\
      & \qquad \ms{ret}\;a_0 \\
      & \quad \} \\
      & \}
    \end{align*}
  \end{subfigure}
  \caption{Allowing if-statements to jump to arbitrary instructions, rather than a terminator}
  \Description{}
  \label{fig:bba-to-anf}
\end{figure}

ANF, however, still lacks a good substitution property, since substituting a value for a variable
can take you out of ANF, making it difficult to express optimizations like $(i + 1) - 1 \to i$ as
rewrite rules. To fix this, we can simply relax the restriction that expressions in a program must
be atomic. This can again trivially be seen to add no excessive power, since we can always introduce
temporary variables via \ms{let}-bindings to make any expression atomic. For full generality, we
will also allow \ms{let}-bindings and \ms{if}-statements \textit{inside} expressions, which again
can be eliminated in the obvious manner, such as by taking
\begin{align*}
  \ms{let}\;x = (\ms{if}\;e\;\{a\}\;\ms{else}\;\{b\}); t &
    \to \ms{if}\;e\;\{\ms{let}\;x = a; t\}\;\ms{else}\;\{\ms{let}\;x = b; t\} \\ 
  & \to \ms{if}\;e\;\{\ms{br}\;\ell(x)\}\;\ms{else}\;\{\ms{br}\;\ell(x)\}\;
        \ms{where}\;\ell(x): \{t\}
\end{align*}

\begin{figure}
  \centering
  \begin{subfigure}[t]{.31\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
      & \quad \ms{if}\;i_0 < n\;\{ \\
      & \qquad \ms{let}\;t = i_0 + 1 \\
      & \qquad \ms{let}\;a_1 = a_0 * t \\
      & \qquad \ms{let}\;i_1 = i_0 + 1 \\
      & \qquad \ms{br}\;\ms{loop}(i_1, a_1) \\
      & \quad \}\;\ms{else}\;\{ \\
      & \qquad \ms{ret}\;a_0 \\
      & \quad \} \\
      & \}
    \end{align*}
    \caption{Program in ANF}
    \label{fig:fact-anf}
  \end{subfigure}%
  \begin{subfigure}[t]{.35\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
      & \quad \ms{if}\;i_0 < n\;\{ \\
      & \qquad \ms{br}\;\ms{loop}(i_0 + 1, a_0 * (i_0 + 1)) \\
      & \quad \}\;\ms{else}\;\{ \\
      & \qquad \ms{ret}\;a_0 \\
      & \quad \} \\
      & \}  \\ \\ \\
    \end{align*}
    \caption{
      Programs \ref{fig:fact-anf} and \ref{fig:fact-subst} after substitution;
      since the result is the same, both programs must be equivalent.
    }
    \label{fig:fact-subst}
  \end{subfigure}\hspace{1em}%
  \begin{subfigure}[t]{.31\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}(1, 1) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
      & \quad \ms{if}\;i_0 < n\;\{ \\
      & \qquad \ms{let}\;i_1 = i_0 + 1 \\
      & \qquad \ms{let}\;a_1 = a_0 * i_1 \\
      & \qquad \ms{br}\;\ms{loop}(i_1, a_1) \\
      & \quad \}\;\ms{else}\;\{ \\
      & \qquad \ms{ret}\;a_0 \\
      & \quad \} \\
      & \} \\
    \end{align*}
    \caption{Optimized ANF program}
    \label{fig:fact-opt}
  \end{subfigure}
  \caption{
    Adding support for expressions, allowing us to perform substitutions of (pure) expressions.
    Optimizations such as common subexpression elimination can be built using substitution as a
    building block.
  }
  \Description{}
  \label{fig:fact-cse}
\end{figure}


This gives us our final \isotopessa language. We can now state
\textit{substitutions}, like, in Figure~\ref{fig:fact-cse}, which can be used to
build up optimizations such as \textit{common-subexpression elimination}.
Substitution, in particular, lets us do algebra \textit{algebra}, for example,
since we know that:
\begin{align*}
  (i_0 + 1, a_0 * (i_0 + 1)) &= (\ms{let}\;(x, y) = (i_0, a_0)\;\ms{in}\;(x + 1, y * (x + 1))) \\
  (1, 1) &= (\ms{let}\;(x, y) = (0, 1)\;\ms{in}\;(x + 1, y * (x + 1)))
\end{align*} 
we can rewrite the program in Figure~\ref{fig:fact-subst-2} to that in
Figure~\ref{fig:fact-dinat}. We can then apply general rewrite rules such as
\textit{dinaturality} (\todo{explain, cite Elgot lore?}) to rewrite
Figure~\ref{fig:fact-dinat} to Figure~\ref{fig:fact-zero}. This allows us to
build up justifications for complex optimizations, such as rewriting
\ref{fig:fact-zero} to \ref{fig:fact-opt}, in terms of simple rewriting steps.
In particular, we can do \textit{complex}, \textit{error-prone} loop and
control-flow graph optimizations by breaking them down into closed set of simple
algebraic steps, with each step rigorously justified via our denotational
semantics

% \begin{itemize}
%   \item 
%   \item We can 
%   \item We can show that our steps are \textit{complete} by showing that quotienting by them gives
%         a model of our denotational semantics
%   \item That's why we use \isotopessa
%   \item But we gain no additional power: SSA $\subseteq$ \isotopessa; this is a retraction
%   (embedding-projection)
%   \item In particular, using the steps, every \isotopessa program can be converted to an SSA program with
%         equivalent semantics, while every SSA program is already a \isotopessa program (just add brackets!)
%   \item Unproven conjecture: this should take \~linear time, and the resuling program should be
%   \~linearly sized. Do on paper?
% \end{itemize}

\begin{figure}
  \begin{minipage}{.5\textwidth}
    \begin{subfigure}{\textwidth}
      \begin{align*}
        & \ms{let}\;n = 10; \\
        & \ms{br}\;\ms{loop}(1, 1) \\
        & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
        & \quad \ms{if}\;i_0 < n\;\{ \\
        & \qquad \ms{br}\;\ms{loop}(i_0 + 1, a_0 * (i_0 + 1)) \\
        & \quad \}\;\ms{else}\;\{ \\
        & \qquad \ms{ret}\;a_0 \\
        & \quad \} \\
        & \}
      \end{align*}
      \caption{Substituted program from Figure \ref{fig:fact-subst}}
      \label{fig:fact-subst-2}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
      \begin{align*}
        & \ms{let}\;n = 10; \\
        & \ms{br}\;\ms{loop}\;(0, 1) \\
        & \ms{where}\;\ms{loop}(x, y): \{\\
        & \quad \ms{let}\;(i_0, a_0) = (x + 1, y * (x + 1)); \\
        & \quad \ms{if}\;i_0 < n\;\{ \\
        & \qquad \ms{br}\;\ms{loop}(i_0, a_0) \\
        & \quad \}\;\ms{else}\;\{ \\
        & \qquad \ms{ret}\;a_0 \\
        & \quad \} \\
        & \}
      \end{align*}
      \caption{Equivalent to Figure \ref{fig:fact-dinat} by \textit{dinaturality}}
      \label{fig:fact-dinat}
    \end{subfigure}
  \end{minipage}%
  \begin{subfigure}[c]{.5\textwidth}
    \begin{align*}
      & \ms{let}\;n = 10; \\
      & \ms{br}\;\ms{loop}( \\
      & \quad \ms{let}\;(x, y) = (0, 1); \\
      & \quad(x + 1, y * (x + 1)) \\
      & ) \\
      & \ms{where}\;\ms{loop}(i_0, a_0): \{\\
      & \quad \ms{if}\;i_0 < n\;\{ \\
      & \qquad \ms{br}\;\ms{loop}( \\
      & \qquad \quad \ms{let}\;(x, y) = (i_0, a_0); \\
      & \qquad \quad (x + 1, y * (x + 1)) \\ 
      & \qquad ) \\
      & \quad \}\;\ms{else}\;\{ \\
      & \qquad \ms{ret}\;a_0 \\
      & \quad \} \\
      & \}
    \end{align*}
    \caption{Equivalent to Figure \ref{fig:fact-subst-2} by substitution}
    \label{fig:fact-zero}
  \end{subfigure}
  \TODO{add arrows via \texttt{tikzmark}}
  \caption{
    Decomposing multi-block rewrites (from \ref{fig:fact-zero} to
    \ref{fig:fact-subst-2}, and therefore to the more optimal program 
    \ref{fig:fact-opt}) into simple algebraic steps. By verifying each step, we can
    verify complex optimizations through decomposition.
  } 
  \Description{}
\end{figure}

\section{Type Theory}

We now give a formal account of \isotopessa, starting with the types. Our types are first order, and
consists of binary sums $A + B$, products $A \otimes B$, the unit type $\mathbf{1}$, and the empty
type $\mb{0}$, all parametrized over a set of base types $X \in \mc{T}$. We write our set of types
as $\ms{Ty}(X)$. We also parametrize over:
\begin{itemize}
  
  \item A set of effects $\epsilon \in \mc{E}$, forming a join-semilattice with bottom element $\bot
  \in \mc{E}$
  
  \item For each pair $A, B \in \ms{Ty}(X)$ and effect $\epsilon \in \mc{E}$, a
  set of \textit{primitive instructions} $f \in \mc{I}_\epsilon(A, B)$, where
  $\epsilon \leq \epsilon' \implies \mc{I}_\epsilon(A, B) \subseteq
  \mc{I}_{\epsilon'}(A, B)$. 
  
  We write $\mc{I}(A, B) = \bigcup_\epsilon\mc{I}_\epsilon(A, B)$,
  $\mc{I}_\epsilon = \bigcup_{A, B}\mc{I}_\epsilon(A, B)$, and $\mc{I} =
  \bigcup_\epsilon\mc{I}_\epsilon$.

\end{itemize}
We'll call a tuple $Sg = (\mc{E}, \mc{T}, \mc{I})$ of types and instructions
over these types an \emph{\isotopessa-signature}.

A (variable )\textit{context} $\Gamma$ is a list of \textit{typing hypotheses}
$\thyp{x}{A}{\epsilon}$, where $x$ is a variable name, $A$ is the type of that
variable, and $\epsilon$ is the effect of using that variable (used when filling
holes with effectful expressions). If $\epsilon = \bot$, we often omit it,
writing $\bhyp{x}{A}$. Similarly, we define a \textit{label-context} to be a
list of \textit{labels} $\lhyp{\ell}{A}$, where $A$ is the parameter type that
must be passed on a jump to the label $\ell$.

\begin{figure}[H]
  \begin{center}
    \begin{grammar}
      <\(A, B, C\)> ::= 
      \(X\)
      \;|\; \(A \otimes B\)
      \;|\; \(\mathbf{1}\)
      \;|\; \(A + B\)
      \;|\; \(\mathbf{0}\)

      <\(a, b, c, e\)> ::= \(x\) 
      \;|\;  \(f\;a\)
      \;|\; \(\letexpr{x}{a}{e}\)
      \alt  \(()\)
      \;|\; \((a, b)\)
      \;|\; \(\letexpr{(x, y)}{a}{e}\)
      \alt  \(\linl{a}\) 
      \;|\; \(\linr{a}\)
      \;|\; \(\labort{a}\)
      \;|\; \(\caseexpr{e}{x}{s}{y}{t}\)
      
      <\(s, t\)> ::= \(\brb{\ell}{a}\) 
      \alt  \(\letstmt{x}{a}{t}\)
      \;|\; \(\letstmt{(x, y)}{a}{t}\)
      \;|\; \(\casestmt{e}{x}{s}{y}{t}\)
      \alt  \(\where{t}{(\wbranch{\ell_i}{x_i: A_i}{t_i},)_i}\)

      <\(\Gamma\)> ::= \(\cdot\) \;|\; \(\Gamma, \thyp{x}{A}{\epsilon}\)

      <\(\ms{L}\)> ::= \(\cdot\) \;|\; \(\ms{L}, \lhyp{\ell}{A}\)
    \end{grammar}
  \end{center}
  \caption{Grammar for \isotopessa, parametrized over an \isotopessa signature}
  \Description{}
  \label{fig:ssa-grammar}
\end{figure}

As shown in Figure~\ref{fig:ssa-grammar}, \isotopessa terms are divided into two
syntactic categories, each of with associated with a judgement:
\begin{itemize}
  \item \emph{Expressions} $a, b, c, e$ typed with the judgement
  $\hasty{\Gamma}{\epsilon}{a}{A}$, which says that under the typing context
  $\Gamma$, the expression $a$ has type $A$ and effect $\epsilon$. We say a term
  is \emph{pure} if it has effect $\bot$; note that whether an expression is
  pure or not depends both on the expression itself and on the purity of the
  variables used in the expression; this is to allow reasoning about impure
  substitutions.
  \item \emph{Regions} $r, s, t$, which recursively define a lexically-scoped
  SSA program with a single entry and (potentially) multiple exits. This is
  typed with the judgement $\haslb{\Gamma}{r}{\ms{L}}$, which states that given
  that $\Gamma$ is live at the unique entry point, $r$ will either loop forever
  or branch to one of the exit labels in $\ell(A) \in \ms{L}$ with an argument
  of type $A$.
\end{itemize}

The typing rules for expressions are given in Figure~\ref{fig:ssa-expr-rules}.
In particular, expressions may be built up from the following fairly standard
primitives:
\begin{itemize}
  \item A variable $x$ in the context $\Gamma$, as typed by \brle{var}. We write $(A, \epsilon) \leq
  (B, \epsilon') \iff A = B \and \epsilon \leq \epsilon'$.
  \item An \emph{primitive instruction} $f \in \mc{I}_\epsilon(A, B)$ applied to an expression
  $\hasty{\Gamma}{\epsilon}{a}{A}$, typed by \brle{op}
  \item Unary and binary \emph{let-bindings}, typed by \brle{let$_1$} and \brle{let$_2$}
  respectively
  \item A \emph{pair} of expressions $\hasty{\Gamma}{\epsilon}{a}{A}$,
  $\hasty{\Gamma}{\epsilon}{b}{B}$, typed by \brle{pair}. Operationally, we interpret this as
  executing $a$, and then $b$, and returning the pair of their values.
  \item An empty tuple $()$, which types in any context by \brle{unit}
  \item Injections, typed by \brle{inl} and \brle{inr}
  \item Pattern matching on sum types, typed by \brle{case}. Operationally, we interpret this as
  executing $e$, and then, if $e$ is a left injection $\ms{inl}\;x$, executing $a$ with its value
  ($x$), otherwise executing $b$.
  \item An operator $\ms{abort}\;e$ allowing us to abort execution if given a value of the empty
  type.
\end{itemize}

\begin{figure}
  \begin{gather*}
    \boxed{\hasty{\Gamma}{\epsilon}{a}{A}} \\
    \prftree[r]{\rle{var}}{\Gamma\;x \leq (A, \epsilon)}{\hasty{\Gamma}{\epsilon}{x}{A}} \qquad
    \prftree[r]{\rle{op}}{\isop{f}{A}{B}{\epsilon}}{\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{f\;a}{B}} \qquad
    \prftree[r]{\rle{let$_1$}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{B}}
      {\hasty{\Gamma}{\epsilon}{\letexpr{x}{a}{b}}{B}} \\
    \prftree[r]{\rle{unit}}{\hasty{\Gamma}{\epsilon}{()}{\mb{1}}} \qquad
    \prftree[r]{\rle{pair}}{\hasty{\Gamma}{\epsilon}{a}{A}}{\hasty{\Gamma}{\epsilon}{b}{B}}
      {\hasty{\Gamma}{\epsilon}{(A, B)}{A \otimes B}} \\
    \prftree[r]{\rle{let$_2$}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\hasty{\Gamma}{\epsilon}{\letexpr{(x, y)}{e}{c}}{C}} \\
    \prftree[r]{\rle{inl}}{\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{\linl{a}}{A + B}} \qquad
    \prftree[r]{\rle{inr}}{\hasty{\Gamma}{\epsilon}{b}{B}}
      {\hasty{\Gamma}{\epsilon}{\linr{b}}{A + B}} \qquad
    \prftree[r]{\rle{abort}}{\hasty{\Gamma}{\epsilon}{a}{\mb{0}}}
      {\hasty{\Gamma}{\epsilon}{\labort{a}}{A}} \\
    \prftree[r]{\rle{case}}
      {\hasty{\Gamma}{\epsilon}{e}{A + B}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{a}{C}}
      {\hasty{\Gamma, \bhyp{y}{A}}{\epsilon}{b}{C}}
      {\hasty{\Gamma}{\epsilon}{\caseexpr{e}{x}{a}{y}{b}}{C}}
  \end{gather*}
  \caption{Rules for typing \isotopessa expressions}
  \Description{}
  \label{fig:ssa-expr-rules}
\end{figure}

\emph{Regions}, on the other hand, can be built up as follows:
\begin{itemize}
  \item A branch to a label $\ell$ with pure argument $a$, typed with \rle{br}.
  
  \item Unary and binary \emph{let-bindings}, typed by \brle{let$_1$} and \brle{let$_2$}
  respectively
  
  \item Pattern matching on sum types, typed by \brle{case}. Operationally, we interpret this as
  executing the (potentially effectful) expression $e$, and then, if $e$ is a left injection
  $\ms{inl}\;x$, executing $r$ with its value ($x$), otherwise executing $s$.
  
  \item \emph{\ms{where}-statements} of the form
  ``$\where{r}{(\wbranch{\ell_i}{x_i}{t_i})_i}$", which consist of a collection
  of mutually recursive regions $\wbranch{\ell_i}{x_i}{t_i}$ and a \emph{terminator
  region} $r$ which may branch to one of $\ell_i$ or an exit label.
\end{itemize}
We previously described SSA programs as being made up out of \emph{basic
blocks}, each of which is made up of a sequence of instructions followed by a
\emph{terminator} and, potentially, a list of strictly dominated basic blocks
this terminator may jump to. Basic blocks are an \emph{implicit} feature of our
grammar: we can view each as a list of unary or binary let-bindings, until we
reach a terminator, which is either an unconditional branch, a
\ms{case}-statement or a \ms{where}-statement, as follows:
\begin{gather*}
  \ms{defs}(\letstmt{x}{e}{r}) = (x, e)::r \qquad 
  \ms{defs}(\letstmt{(x, y)}{e}{r}) = ((x, y), e)::r \\
  \ms{defs}(r) = [] \quad \text{otherwise} \\
  \ms{terminator}(\letstmt{x}{e}{r}) 
  = \ms{terminator}(\letstmt{(x, y)}{e}{r}) 
  = \ms{terminator}(r) \\
  \ms{terminator}(r) = r \quad \text{otherwise} \\
  \ms{bb}(r) = (\ms{defs}(r), \ms{terminator}(r))
\end{gather*}
Note in particular that the region $r$ in a \ms{where}-statement
$\where{r}{(\wbranch{\ell_i}{x_i}{t_i})_i}$ is best interpreted as a terminator
rather than an entry-block even if of the form, e.g., $r = \letstmt{x}{e}{s}$.
The entry block is instead the \emph{implicit} basic-block made up of any
let-bindings surrounding the \ms{where}-statement. The key difference is that
variables defined in $r$ are \emph{not} visible in the blocks $t_i$, whereas
variables defined in the entry-block are. While at first glance this can be
unintuitive, the additional generality greatly simplifies rewriting, and we can
always ``normalize away'' this feature, since our equational theory generally
admits that, \emph{if} both sides are well-typed and there is no shadowing,
\begin{align*}
  \where{(\letexpr{x}{e}{r})}{(\wbranch{\ell_i}{x_i}{t_i})_i}
  &= (\letexpr{x}{e}{(\where{r}{(\wbranch{\ell_i}{x_i}{t_i})_i})}) \\
  \where{(\letexpr{(x, y)}{e}{r})}{(\wbranch{\ell_i}{x_i}{t_i})_i}
  &= (\letexpr{(x, y)}{e}{(\where{r}{(\wbranch{\ell_i}{x_i}{t_i})_i})})
\end{align*}

\begin{figure}
  \begin{gather*}
    \boxed{\haslb{\Gamma}{r}{\ms{L}}} \\
    \prftree[r]{\rle{br}}{\hasty{\Gamma}{\bot}{a}{A}}{\ms{L}\;\ell = A}
      {\haslb{\Gamma}{\brb{\ell}{a}}{\ms{L}}} \qquad
    \prftree[r]{\rle{let$_1$-r}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      {\haslb{\Gamma}{\letstmt{x}{a}{r}}{\ms{L}}} \\
    \prftree[r]{\rle{let$_2$-r}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\haslb{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{r}{\ms{L}}}
      {\haslb{\Gamma}{\letstmt{(x, y)}{e}{r}}{\ms{L}}} \\
    \prftree[r]{\rle{case-r}}
      {\hasty{\Gamma}{\epsilon}{e}{A + B}}
      {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      {\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}}}
      {\haslb{\Gamma}{\casestmt{e}{x}{r}{y}{s}}{\ms{L}}} \\
    \prftree[r]{\rle{cfg}}
      {\haslb{\Gamma}{r}{\ms{L}, (\lhyp{\ell_i}{A_i},)_i}}
      {\forall i. \haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
      {\haslb{\Gamma}{\where{r}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}{\ms{L}}}
  \end{gather*}
  \caption{Rules for typing \isotopessa regions}
  \Description{}
  \label{fig:ssa-reg-rules}
\end{figure}

\subsection{Metatheory}

We can now begin to state the syntactic metatheory of \isotopessa. One of the
most important metatheorems, and a basic santity check of our type theory, is
\emph{weakening}; essentially, if things typecheck in a context $\Delta$, and
$\Gamma$ contains all the variables of $\Delta$ (written $\Gamma \leq \Delta$,
pronounced ``$\Gamma$ \emph{weakens} $\Delta$''), then these things should
typecheck in the context $\Gamma$ as well. That is, ``$\Gamma$ typechecks more
terms than $\Delta$''.
 
Making things more formal, we introduce the rules for weakening $\Gamma \leq
\Delta$ in the first part of Figure \ref{fig:ssa-meta-rules}: \brle{wk-nil} says
that the empty context weakens itself, \brle{wk-skip} says that if $\Gamma$
weakens $\Delta$, then $\Gamma$ with an arbitrary variable added also weakens
$\Delta$, and \brle{wk-cons} says that if $\Gamma$ weakens $\Delta$ and
$\epsilon \leq \epsilon'$, then $\Gamma$ with $\thyp{x}{A}{\epsilon}$ added
weakens $\Delta, \thyp{x}{A}{\epsilon'}$. It is easy to see that weakening
defined in this manner induces a partial order on contexts.

We may go further and introduce weakening for \emph{label contexts} $\ms{L} \leq
\ms{K}$ analogously, except that we will flip the ordering such that $\ms{L}$
weakens $\ms{K}$ if it contains \emph{less}, rather than \emph{more}, labels
than $\ms{K}$. This is a bit unconventional, since in this case $\ms{L}$ types
\emph{less} regions than $\ms{K}$, but it will make our metatheory and
denotational semantics come out more clearly, since it corresponds to
label-contexts being ``on the right'' (with variable contexts ``on the left'').
In particular, in Figure \ref{fig:ssa-meta-rules}, we introduce the rules
\brle{lwk-nil}, which says that the empty label context weakens itself,
\brle{lwk-skip}, which says that if $\ms{L}$ weakens $\ms{K}$, then $\ms{L}$
weakens $\ms{K}$ with an arbitrary label added, and \brle{lwk-cons}, which says
that if $\ms{L}$ weakens $\ms{K}$, then $\ms{L}$ with a label $\lhyp{\ell}{A}$
added weakens $\ms{K}$ with the same label added. It is easy to see that this
induces a partial order on label contexts.

\begin{figure}
  \begin{gather*}
    \boxed{\Gamma \leq \Delta} \\
    \prftree[r]{\rle{wk-nil}}{}{\cdot \leq \cdot} \qquad
    \prftree[r]{\rle{wk-skip}}{\Gamma \leq \Delta}{\Gamma, \thyp{x}{A}{\epsilon} \leq \Delta} \qquad
    \prftree[r]{\rle{wk-cons}}{\Gamma \leq \Delta}{\epsilon \leq \epsilon'}
      {\Gamma, \thyp{x}{A}{\epsilon} \leq \Delta, \thyp{x}{A}{\epsilon'}} \\
    \boxed{\ms{L} \leq \ms{K}} \\
    \prftree[r]{\rle{lwk-nil}}{}{\cdot \leq \cdot} \qquad
    \prftree[r]{\rle{lwk-skip}}{\ms{L} \leq \ms{K}}{\ms{L} \leq \ms{K}, \lhyp{\ell}{A}} \qquad
    \prftree[r]{\rle{lwk-cons}}{\ms{L} \leq \ms{K}}
      {\ms{L}, \lhyp{\ell}{A} \leq \ms{K}, \lhyp{\ell}{A}} \\
    \boxed{\issubst{\gamma}{\Gamma}{\Delta}} \\
    \prftree[r]{\rle{sb-nil}}{}{\issubst{\cdot}{\Gamma}{\cdot}} \qquad
    \prftree[r]{\rle{sb-skip}}{}{\issubst{\gamma}{\Gamma}{\Delta}}
      {\issubst{\gamma, x \mapsto e}{\Gamma}{\Delta}} \qquad
    \prftree[r]{\rle{sb-cons}}{\issubst{\gamma}{\Gamma}{\Delta}}{\hasty{\Gamma}{\epsilon}{e}{A}}
      {\issubst{\gamma, x \mapsto e}{\Gamma}{\Delta, \thyp{x}{A}{\epsilon}}} \\
    \boxed{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}} \\
    \prftree[r]{\rle{ls-nil}}{}{\lbsubst{\Gamma}{\cdot}{\cdot}{\ms{K}}} 
    \qquad
    \prftree[r]{\rle{ls-skip}}
      {\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}
      {\lbsubst{\Gamma}{\sigma, \ell(x) \mapsto r}{\ms{L}}{\ms{K}}} \\
    \prftree[r]{\rle{ls-cons}}
      {\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}{\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{K}}}
      {\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}
      {\lbsubst{\Gamma}{\sigma, \ell(x) \mapsto r}{\ms{L}, \lhyp{\ell}{A}}{\ms{K}}}
  \end{gather*}
  \caption{Rules for typing \isotopessa weakening and substitution}
  \Description{}
  \label{fig:ssa-meta-rules}
\end{figure}

We can now state weakening formally as follows:
\begin{lemma}[Weakening]
  Given $\Gamma \leq \Delta$, $\epsilon \leq \epsilon'$, and $\ms{L} \leq \ms{K}$, we have that:
  \begin{enumerate}[label=(\alph*)]
    \item $\hasty{\Delta}{\epsilon}{a}{A} \implies \hasty{\Gamma}{\epsilon'}{a}{A}$
    \item $\haslb{\Delta}{r}{\ms{L}} \implies \haslb{\Gamma}{r}{\ms{K}}$
    \item $\issubst{\sigma}{\Gamma}{\Xi} \implies \issubst{\sigma}{\Delta}{\Xi}$ and 
          $\issubst{\sigma}{\Xi}{\Gamma} \implies \issubst{\sigma}{\Xi}{\Delta}$
    \item $\lbsubst{\Delta}{\sigma}{\ms{L}}{\ms{K}} \implies \lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}$
  \end{enumerate}
\end{lemma}
\begin{proof}
  By induction. \todo{pointer to formalization?}
\end{proof}

If we look at the proof of variable weakening, we might arrive at the alternate
statement that all the variables in $\Delta$ are also available with the same
type in $\Gamma$, i.e., if $\hasty{\Delta}{\epsilon}{x}{A} \implies
\hasty{\Gamma}{\epsilon}{x}{A}$, then anything which can be typed in $\Delta$
can be typed in $\Gamma$. More generally, we might ask if every variable
$\hasty{\Delta}{\epsilon}{x}{A}$ in $\Delta$ can be associated with a term
$\hasty{\Gamma}{\epsilon}{\gamma_x}{A}$ which is well-typed in $\Gamma$. An
assignment of such variables $\gamma : x \mapsto \gamma_x$ is called a
\emph{substitution}, which we can type with the judgement
$\issubst{\gamma}{\Gamma}{\Delta}$ as per the rules given in Figure
\ref{fig:ssa-reg-rules}. In particular,
\begin{itemize}
  \item \brle{sb-nil} says that the empty substitution takes every context to
  the empty context, while \brle{sb-skip} says that we can ignore variables
  defined in a substitution which do not appear in the right-hand side of the
  substitution well-typedness judgement. Together, these say that \emph{every}
  substitution can be interpreted as taking every context to the empty context,
  i.e., $\forall \gamma, \Gamma. \issubst{\gamma}{\Gamma}{\cdot}$.
  \item \brle{sb-cons} says that if $\gamma$ takes $\Gamma$ to $\Delta$ and
  $\hasty{\Gamma}{\epsilon}{e}{A}$, then $\gamma$ with the additional
  substitution $x \mapsto e$ adjoined takes $\Gamma$ to $\Delta,
  \thyp{x}{A}{\epsilon}$
\end{itemize}
To \emph{use} a substitution, we simply need to perform standard
capture-avoiding substitution, as made explicit in Figure
\ref{fig:ssa-subst-def}.

\begin{figure}
  \begin{gather*}
    [\gamma]x = \gamma(x) \qquad
    [\gamma](\letexpr{x}{a}{e}) = \letexpr{x}{[\gamma]a}{[\gamma]e} \qquad
    [\gamma](a, b) = ([\gamma]a, [\gamma]b) \qquad
    [\gamma]() = () \\
    [\gamma](\letexpr{(x, y)}{a}{e})
    = \letexpr{(x, y)}{[\gamma]a}{[\gamma]e} \qquad
    [\gamma](\linl{a}) = \linl{[\gamma]a} \qquad
    [\gamma](\linr{b}) = \linr{[\gamma]b} \\
    [\gamma](\caseexpr{e}{x}{a}{y}{b}) =
    \caseexpr{[\gamma]e}{x}{[\gamma]a}{y}{[\gamma]b} \\
    [\gamma](\labort{a}) = \labort{[\gamma]a} 
    \\ \\
    [\gamma](\brb{\ell}{a}) = \brb{\ell}{[\gamma]a} \qquad
    [\gamma](\letstmt{x}{a}{r}) = \letstmt{x}{[\gamma]a}{[\gamma]r} \\
    [\gamma](\letstmt{(x, y)}{e}{r}) = \letstmt{(x, y)}{[\gamma]e}{[\gamma]r} \\
    [\gamma](\casestmt{e}{x}{r}{y}{s}) 
    = \casestmt{[\gamma]e}{x}{[\gamma]r}{y}{[\gamma]s} \\
    [\gamma](\where{r}{(\wbranch{\ell_i}{x_i}{t_i},)_i}) =
    \where{[\gamma]r}{(\wbranch{\ell_i}{x_i}{[\gamma]t_i},)_i} 
    \\ \\
    [\gamma](\cdot) = \cdot \qquad
    [\gamma](\gamma', x \mapsto e) 
    = ([\gamma]\gamma', x \mapsto [\gamma]e)
    \\ \\
    [\gamma](\cdot) = \cdot \qquad
    [\gamma](\sigma, \ell(x) \mapsto r) 
    = ([\gamma]\sigma, \ell(x) \mapsto [\gamma]r)
    \\ \\
    (\sigma, \ell(x) \mapsto r)(\ell, a) = [a/x]r \qquad
    (\sigma, \kappa(x) \mapsto r)(\ell, a) = \sigma(\ell, a)
    \\ \\
    [\sigma](\brb{\ell}{a}) = \sigma(\ell, a) \qquad
    [\sigma](\letstmt{x}{a}{r}) = \letstmt{x}{a}{[\sigma]r} \\
    [\sigma](\letstmt{(x, y)}{e}{r}) = \letstmt{(x, y)}{e}{[\sigma]r} \\
    [\sigma](\casestmt{e}{x}{r}{y}{s}) = \casestmt{e}{x}{[\sigma]r}{y}{[\sigma]s} \\
    [\sigma](\where{r}{(\wbranch{\ell_i}{x_i}{t_i},)_i}) =
    \where{([\sigma]r)}{(\wbranch{\ell_i}{x_i}{[\sigma]t_i},)_i} 
    \\ \\
    [\sigma](\cdot) = \cdot \qquad
    [\sigma](\sigma', \ell(x) \mapsto r) 
    = ([\sigma]\sigma', \ell(x) \mapsto [\sigma]r)
  \end{gather*}
  \caption{ 
    Capture-avoiding (label) substititon for \isotopessa terms, regions, and
    (label) substitutions; in particular, we assume bound variables and labels
    are $\alpha$-converted so as not to appear in $\gamma$/$\sigma$. 
  }
  \Description{}
  \label{fig:ssa-subst-def}
\end{figure}

This gives us everything we need to state the \emph{substitution lemma}, which
is as follows:
\begin{lemma}[Substitution]
  Given $\issubst{\gamma}{\Gamma}{\Delta}$, we have that:
  \begin{enumerate}[label=(\alph*)]
    \item $\hasty{\Delta}{\epsilon}{a}{A} \implies \hasty{\Gamma}{\epsilon}{[\gamma]a}{A}$ 
    \item $\haslb{\Delta}{r}{\ms{L}} \implies \haslb{\Gamma}{[\gamma]r}{\ms{L}}$
    \item $\issubst{\rho}{\Delta}{\Xi} \implies \issubst{[\gamma]\rho}{\Gamma}{\Xi}$
    \item $\lbsubst{\sigma}{\Gamma}{\ms{L}}{\ms{K}} \implies \lbsubst{[\gamma]\sigma}{\Delta}{\ms{L}}{\ms{K}}$
  \end{enumerate}
\end{lemma}
\begin{proof}
  By induction. \todo{pointer to formalization?}
\end{proof}
Note in particular that this allows us to take the \emph{composition}
$\issubst{[\gamma']\gamma}{\Gamma'}{\Delta}$ of substitutions
$\issubst{\gamma'}{\Gamma'}{\Gamma}$ and $\issubst{\gamma}{\Gamma}{\Delta}$; the
composition associates as expected: $[[\gamma_1]\gamma_2]\gamma_3 =
[\gamma_1]([\gamma_2]\gamma_3)$, and has identity $[\ms{id}]\gamma = \gamma$,
yielding a category of substitutions with variable contexts $\Gamma$ as objects.

Finally, just as we can substitute generalizes weakening by substituting
expressions for variables, we can generalize label weakening by substituting
\emph{labels} for \emph{(parametrized) regions} via \emph{label substitution}.
In particular, a label-substitution $\lbsubst{\sigma}{\Gamma}{\ms{L}}{\ms{K}}$
maps every label $\ell(A) \in \ms{L}$ to a region $\haslb{\Gamma, x :
A}{r}{\ms{K}}$ parametrized by $x : A$. As shown in Figure
\ref{fig:ssa-subst-def}, we may then define label-substitution recursively in
the obvious manner, mapping $\ms{br}\;\ell\;a$ to $[a/x]r$ as a base case. We
can similarly define the composition of label substitutions $[\sigma']\sigma$ in
the expected manner. This allows us to state \emph{label substitution} as
follows:

\begin{lemma}[Label substitution]
  Given $\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}$, we have that
  \begin{enumerate}[label=(\alph*)]
    \item $\haslb{\Gamma}{r}{\ms{L}} \implies \haslb{\Gamma}{[\sigma]r}{\ms{K}}$
    \item $\lbsubst{\Gamma}{\kappa}{\ms{L}}{\ms{J}} 
      \implies \lbsubst{\Gamma}{[\sigma]\kappa}{\ms{K}}{\ms{J}}$
  \end{enumerate}
\end{lemma}

Label substitution is powerful since it allows us to reason directly about
program transformations which splice and manipulate the control-flow graph.

\TODO{this...}

\section{Equational Theory}

\subsection{Expressions}

We can now give an equational theory for \isotopessa expressions. In particular,
we will inductively define an equivalence relation
$
\tmeq{\Gamma}{\epsilon}{a}{a'}{A}
$
on terms $a, a'$ for each context $\Gamma$, effect $\epsilon$, and type $A$. For each of the rules
we will present, we assume the rule is valid if and only if \emph{both sides} of the rule are
well-typed. We also assume that variables are $\alpha$-converted as appropriate to avoid shadowing;
our formalization uses de-Bruijn indices, but we stick with names in this exposition for simplicity.

The rules for this relation can be roughly split into \emph{rewriting rules}, which denote when two
particular expressions have equivalent semantics, and \emph{congruence rules}, which govern how
rewrites can be composed to enable equational reasoning. In particular, our congruence rules, given
in Figure~\ref{fig:ssa-expr-congr-rules}, consist of:
\begin{itemize}
  \item \brle{refl}, \brle{symm}, \brle{trans}, which state that
  $\tmeq{\Gamma}{\epsilon}{\cdot}{\cdot}{A}$ is reflexive, transitive, and symmetric respectively
  for each choice of $\Gamma, \epsilon, A$, and therefore an equivalence relation.
  \item \brle{let$_1$}, \brle{let$_2$}, \brle{pair}, \brle{inl}, \brle{inr}, \brle{case}, and
  \brle{abort}, which state that $\tmeq{\Gamma}{\epsilon}{\cdot}{\cdot}{A}$ is a \emph{congruence}
  with respect to the corresponding expression contructor, and, in particular, that the expression
  constructors are well-defined functions on the quotient of expressions up to $\teqv$.
\end{itemize} 
We also include the following \emph{type-directed} rules as part of our congruence relation:
\begin{itemize}
  \item \brle{initial}, which equates \emph{all} terms in a context containing the empty type
  $\mb{0}$, since we will deem any such context to be \emph{unreachable} by control flow. In
  particular, any instruction or function call returning $\mb{0}$ is assumed to diverge, similarly
  to Rust's ``never type'' ``$!$".
  \item \brle{terminal}, which equats all \emph{pure} terms of unit type $\mb{1}$. Note that
  \emph{impure} terms may be disequal, since while their result values are the same, their side
  effects may differ!
\end{itemize}

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{refl}}{\hasty{\Gamma}{\epsilon}{a}{A}}{\tmeq{\Gamma}{\epsilon}{a}{a}{A}} \qquad
    \prftree[r]{\rle{trans}}
      {\tmeq{\Gamma}{\epsilon}{a}{b}{A}}
      {\tmeq{\Gamma}{\epsilon}{b}{c}{A}} 
      {\tmeq{\Gamma}{\epsilon}{a}{c}{A}} \qquad
    \prftree[r]{\rle{symm}}
      {\tmeq{\Gamma}{\epsilon}{a}{b}{A}}
      {\tmeq{\Gamma}{\epsilon}{b}{a}{A}}
    \\
    \prftree[r]{\rle{let$_1$}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
      {\tmeq{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{b'}{B}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{x}{a}{b}}{\letexpr{x}{a'}{b'}}{B}} 
    \\
    \prftree[r]{\rle{pair}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
      {\tmeq{\Gamma}{\epsilon}{b}{b'}{B}}
      {\tmeq{\Gamma}{\epsilon}{(a, b)}{(a', b)}{A \otimes B}}
    \\
    \prftree[r]{\rle{let$_2$}}
      {\tmeq{\Gamma}{\epsilon}{e}{e'}{A \otimes B}}
      {\tmeq{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{c'}{C}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{(x, y)}{e}{c}}{\letexpr{(x, y)}{e'}{c'}}{C}}
    \\
    \prftree[r]{\rle{inl}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
      {\tmeq{\Gamma}{\epsilon}{\linl{a}}{\linl{a'}}{A + B}} \qquad
    \prftree[r]{\rle{inr}}
      {\tmeq{\Gamma}{\epsilon}{b}{b'}{B}}
      {\tmeq{\Gamma}{\epsilon}{\linr{b}}{\linr{b'}}{A + B}} \qquad
    \\
    \prftree[r]{\rle{case}}
      {\tmeq{\Gamma}{\epsilon}{e}{e'}{A + B}}
      {\tmeq{\Gamma, \bhyp{x}{A}}{\epsilon}{a}{a'}{C}}
      {\tmeq{\Gamma, \bhyp{y}{B}}{\epsilon}{b}{b'}{C}}
      {\tmeq{\Gamma}{\epsilon}{\caseexpr{e}{x}{a}{y}{b}}{\caseexpr{e'}{x}{a'}{y}{b'}}{C}}
    \\
    \prftree[r]{\rle{abort}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{\mb{0}}}
      {\tmeq{\Gamma}{\epsilon}{\labort{a}}{\labort{a'}}{A}}
    \\
    \prftree[r]{\rle{initial}} 
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{a'}{A}}
      {\exists x, \Gamma\;x = (\mb{0}, \bot)}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
      \qquad
    \prftree[r]{\rle{terminal}}
      {\hasty{\Gamma}{\bot}{a}{\mb{1}}}
      {\hasty{\Gamma}{\bot}{a'}{\mb{1}}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{\mb{1}}}
  \end{gather*}
  \caption{Congruence rules for \isotopessa expressions}
  \Description{}
  \label{fig:ssa-expr-congr-rules}
\end{figure}

We may group the rest of our rules according to the relevant constructor, i.e. $\ms{let}$ (unary and
binary) and $\ms{case}$. In particular, for unary $\ms{let}$, we have the following rules,
summarized in Figure~\ref{fig:ssa-unary-let-expr}:
\begin{itemize}
  \item \brle{let$_1$-$\beta$}, which allows us to substitute the bound variable in $x$ the
  let-statement $\letexpr{x}{a}{b}$ with its definition $a$, yielding $[a/x]b$. Note that we require
  $\hasty{\Gamma}{\bot}{a}{A}$; i.e., $a$ must be \emph{pure}.
  \brle{let$_1$-$\beta$} can be combined with \brle{initial} to derive the more convenient
  rule \brle{initial-expr}:
  \begin{gather*}
    \prftree[r]{\rle{initial-expr}} 
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{a'}{A}}
      {\exists e, \hasty{\Gamma}{\bot}{e}{\mb{0}}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
  \end{gather*}
  This states that any context in which a \emph{pure} term of empty type can be constructed equates
  all terms. Note in particular that this means divergent instructions must have impure effect!

  \item \brle{let$_1$-$\eta$}, which is the standard $\eta$-rule for \ms{let}. This is included as a
  separate rule since, while it follows trivially from $\beta$ for pure $a$, we also want to
  consider \emph{impure} expressions with some effect $e \neq \bot$.
  
  \item Rules \brle{let$_1$-op}, \brle{let$_1$-pair}, \brle{let$_1$-inl}, and \brle{let$_1$-inr},
  \brle{let$_1$-abort}, and \brle{let$_1$-case} which allow us to ``pull'' a let-statement out of
  any of the other expression constructors; operationally, this is saying that the bound expression
  we pull out is evaluated before the rest of the \ms{let}-binding.
  
  For example, \brle{let$_1$-case} says that, if both
  $\letexpr{z}{\caseexpr{e}{x}{a}{y}{b}}{d}$ and
  $\caseexpr{e}{x}{\letexpr{z}{a}{d}}{y}{\letexpr{z}{b}{d}}{y}$,
  are well typed, then both must have the same behaviour:
  \begin{enumerate}
    \item Compute $e$
    \item If $e = \linl{e_l}$, compute $[e_l/x]a$, else, if $e = \linr{e_r}$, compute $[e_r/y]b$;
          store this value as $z$
    \item Compute $d$ given our value for $z$
  \end{enumerate}
  Note in particular that, since both sides are well-typed, $d$ cannot depend on either $x$ or $y$.
\end{itemize}

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{let$_1$-$\beta$}}
      {\hasty{\Gamma}{\bot}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{B}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{x}{a}{b}}{[b/x]a}{B}}
    \qquad
    \prftree[r]{\rle{let$_1$-$\eta$}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{x}{a}{x}}{a}{A}} 
    \\
    \prftree[r]{\rle{let$_1$-op}}
      {\isop{f}{A}{B}{\epsilon}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{y}{f\;a}{c}}{\letexpr{x}{a}{\letexpr{f\;x}{y}{c}}}{C}}
    \\
    \prftree[r]{\rle{let$_1$-let$_1$}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{B}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\tmeq{\Gamma}{\epsilon}
        {\letexpr{y}{(\letexpr{x}{a}{b})}{c}}
        {\letexpr{x}{a}{\letexpr{y}{b}{c}}}{C}}
    \\
    \prftree[r]{\rle{let$_1$-let$_2$}}
      {\hasty{\Gamma}{\epsilon}{e}{A \times B}}
      {\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{C}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{z}{C}}{\epsilon}{d}{D}}
      {\tmeq{\Gamma}{\epsilon}
        {\letexpr{z}{(\letexpr{(x, y)}{e}{c})}{d}}
        {\letexpr{(x, y)}{e}{\letexpr{z}{c}{d}}}{C}}
    \\
    \prftree[r]{\rle{let$_1$-inl}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A + B}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{y}{C}}{\epsilon}{d}{D}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{y}{\linl{a}}{c}}{\letexpr{x}{a}{\letexpr{y}{\linl{x}}{c}}}{C}}
    \\
    \prftree[r]{\rle{let$_1$-inr}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\hasty{\Gamma, \bhyp{x}{A + B}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{y}{C}}{\epsilon}{d}{D}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{y}{\linr{b}}{c}}{\letexpr{x}{b}{\letexpr{y}{\linr{x}}{c}}}{C}}
    \\
    \prftree[r]{\rle{let$_1$-abort}}
      {\hasty{\Gamma}{\epsilon}{a}{\mb{0}}}
      {\hasty{\Gamma, \bhyp{y}{A}}{\epsilon}{b}{B}}
      {\tmeq{\Gamma}{\epsilon}
        {\letexpr{y}{\labort{b}}{b}}
        {\letexpr{x}{a}{\letexpr{y}{\labort{x}}{b}}}{B}}
    \\
    \prftree[r]{\rle{let$_1$-case}}
      {\hasty{\Gamma}{\epsilon}{e}{A + B}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{a}{C}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{b}{C}}
      {\hasty{\Gamma, \bhyp{z}{C}}{\epsilon}{d}{D}}
      { 
        \prfStackPremises
        {\Gamma \vdash_\epsilon \letexpr{z}{(\caseexpr{e}{x}{a}{y}{b})}{d}}
        {\hspace{6em} \teqv \caseexpr{e}{x}{\letexpr{z}{a}{d}}{y}{\letexpr{z}{b}{d}} : D}
      }
  \end{gather*}
  \Description{}
  \caption{Rewriting rules for \isotopessa unary \ms{let} expressions}
  \label{fig:ssa-unary-let-expr}
\end{figure}

Handling the other type constructors is a little simpler: by providing a ``binding'' rule, we
generally only need to specify how to interact with $\ms{let}_1$, as well as an $\eta$ and $\beta$
rule; interactions with the other constructors can then be derived. For example, consider the rules
for $\ms{let}_2$ given in \ref{fig:ssa-let2-case-expr}; we have:
\begin{itemize}
  \item \brle{let$_2$-$\eta$}, which is the standard $\eta$-rule for binary \ms{let}-bindings
  \item \brle{let$_2$-pair}, which acts like a slightly generalized $\beta$-rule, since we can
  derive $\beta$ reduction as follows: given pure $\hasty{\Gamma}{\bot}{a}{A}$ and
  $\hasty{\Gamma}{\bot}{b}{B}$, we have
  $$
  (\letexpr{(x, y)}{(a, b)}{c}) 
  \teqv (\letexpr{x}{a}{\letexpr{y}{b}{c}})
  \teqv ([a/x](\letexpr{y}{b}{c}))
  \teqv ([a/x][b/y]c)
  $$
  We state the rule in a more general form to allow for impure $a$ and $b$, as well as to simplify
  certain proofs.
  \item \brle{let$_2$-bind}, which allows us to ``pull'' out the bound value of a binary
  \ms{let}-expression into its own unary \ms{let}-expression; operationally, this just says that
  we execute the bound value before executing the binding itself.
\end{itemize}
This is enough to allow us to define our interactions with the other expression constructors: for
example, to show that we can lift an operation $f$ out of a binary $\ms{let}$-binding, rather than
adding a separate rule, we can instead derive (types omitted for simplicity) it from
\brle{let$_2$-bind} and \brle{let$_1$-op} as follows:
\begin{align*}
  (\letexpr{(x, y)}{f\;a}{b})
  &\teqv (\letexpr{z_f}{f\;a}{\letexpr{(x, y)}{z}{b}}) \\
  &\teqv (\letexpr{z_a}{a}{\letexpr{z_f}{f\;z_a}{\letexpr{(x, y)}{z}{b}}}) \\
  &\teqv (\letexpr{z_a}{a}{\letexpr{(x, y)}{f\;z_a}{b}})
\end{align*}

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{let$_2$-pair}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{(x, y)}{(a, b)}{c}}{\letexpr{x}{a}{\letexpr{y}{b}{c}}}{C}}
    \\
    \prftree[r]{\rle{let$_2$-$\eta$}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\tmeq{\Gamma}{\epsilon}{\letexpr{(x, y)}{e}{(x, y)}}{e}{A \otimes B}} 
    \\
    \prftree[r]{\rle{let$_2$-bind}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\tmeq{\Gamma}{\epsilon}
        {\letexpr{(x, y)}{e}{c}}
        {\letexpr{z}{e}{\letexpr{(x, y)}{z}{c}}}{C}}
    \\
    \prftree[r]{\rle{case-inl}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{d}{C}}
      {\tmeq{\Gamma}{\epsilon}{\caseexpr{\linl{a}}{x}{c}{y}{d}}{\letexpr{x}{a}{c}}{C}}
    \\
    \prftree[r]{\rle{case-inr}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{d}{C}}
      {\tmeq{\Gamma}{\epsilon}{\caseexpr{\linr{b}}{x}{c}{y}{d}}{\letexpr{y}{b}{d}}{C}}
    \\
    \prftree[r]{\rle{case-$\eta$}}
      {\hasty{\Gamma}{\epsilon}{e}{A + B}}
      {\tmeq{\Gamma}{\epsilon}{\caseexpr{e}{x}{\linl{x}}{y}{\linr{y}}}{e}{A + B}}
    \\
    \prftree[r]{\rle{case-bind}}
      {\hasty{\Gamma}{\epsilon}{e}{A + B}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{C}}
      {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{d}{C}}
      {\tmeq{\Gamma}{\epsilon}{\caseexpr{e}{x}{c}{y}{d}}
      {\letexpr{z}{e}{\caseexpr{z}{x}{c}{y}{d}}}{C}}
  \end{gather*}
  \Description{}
  \caption{Rewriting rules for \isotopessa binary \ms{let} and \ms{case} expressions}
  \label{fig:ssa-let2-case-expr}
\end{figure}

Similarly, it is enough to give $\eta$, $\beta$, and binding rules for \brle{case} expressions. 
In particular, we have that
\begin{itemize}
  \item \brle{case-inl} and \brle{case-inr} serve as $\beta$-reduction rules, telling us that
  \ms{case}-expressions given an injection as an argument have the expected operational behaviour.
  Note that we reduce to a \ms{let}-expression rather than perform a substitution to allow for
  impure discriminants.
  \item \brle{case-$\eta$} is the standard $\eta$-rule for \ms{case}-expressions.
  \item \brle{case-bind} allows us to ``pull'' out the bound value of the discriminant into
  it's own \ms{let}-expression; again, operationally, this just says that we need to evaluate
  the discriminant before executing the \ms{case}-expression.
\end{itemize}
It's interesting that this is enough, along with the \brle{let-case} rule and friends, to derive the
distributivity properties we would expect well-behaved \ms{case}-expressions to have. For example,
we have that
\begin{align*}
  f(\caseexpr{e}{x}{a}{y}{b}) 
  &\teqv (\letexpr{z}{\caseexpr{e}{x}{a}{y}{b}}{f\;z}) \\
  &\teqv \caseexpr{e}{x}{\letexpr{z}{a}{f\;z}}{y}{\letexpr{z}{b}{f\;z}} \\
  &\teqv \caseexpr{e}{x}{f\;a}{y}{f\;b}
\end{align*}
and likewise for more complicated distributivity properties involving, e.g., \ms{let}-bindings.

The case for other the other constructors is even more convenient: no additional rules are required
at all to handle operations, pairs, and injections. For example, we can derive the expected
bind-rule for operations as follows:
\begin{align*}
  f\;a \teqv (\letexpr{y}{f\;a}{y})
  \teqv (\letexpr{x}{a}{\letexpr{y}{f\;x}{y}})
  \teqv (\letexpr{x}{a}{f\;x})
\end{align*}

This completes the equational theory for \isotopessa terms; in Section \ref{ssec:completeness}, we
will show that this is enough to state a relatively powerful completeness theorem.

\subsection{Regions}

We now come to the equational theory for regions, which is similar to that for terms, except that we
also need to support control-flow graphs. As before, we will split our rules into a set of
\emph{cogruence rules} and, for each region constructor, \emph{rewriting rules} based on that
constructor's semantics. Our congruence rules, given in Figure~\ref{fig:ssa-reg-congr-rules}, are
quite standard; we have:
\begin{itemize}
  \item As for terms, \brle{refl}, \brle{trans}, and \brle{symm} state that
  $\lbeq{\Gamma}{\cdot}{\cdot}{\ms{L}}$ is an equivalence relation for all $\Gamma$, $\ms{L}$.
  \item Similarly, \brle{let$_1$}, \brle{let$_2$}, \brle{case}, and \brle{cfg} state that
  $\lbeq{\Gamma}{\cdot}{\cdot}{\ms{L}}$ is a congruence over the respective region constructors;
  \emph{as well as} the equivalence relation on terms $\tmeq{\Gamma}{\epsilon}{\cdot}{\cdot}{A}$.
  \item \brle{initial} states that any context containing the empty type $\mb{0}$ equates all
  regions, by a similar reasoning to the rules for terms. Note that we do not require an analogue to
  the \brle{terminal} rule (for example, for regions targeting $\ms{L} = \lhyp{\ell}{\mb{1}}$),
  since it will follow from the version for terms; this is good, since the concept of a ``pure''
  region has not yet been defined.
\end{itemize}
Our rewriting rules for unary \ms{let}-statements, given in Figure~\ref{fig:ssa-reg-unary-let}, are
analogous to those for unary \ms{let}-expressions:
\begin{itemize}
  \item \brle{let$_1$-$\beta$} allows us to perform $\beta$-reduction of \emph{pure} expressions
  into regions; unlike for terms, we do not need an $\eta$-rule
  \item Exactly like for \ms{let}-expressions, \brle{let$_1$-op}, \brle{let$_1$-pair},
  \brle{let$_1$-inl}, \brle{let$_1$-inr}, \brle{let$_1$-abort}, and \brle{let$_1$-case} allow us
  to pull out nested subexpressions of the bound value of a \ms{let}-statement into their own
  unary \ms{let}-statement
\end{itemize}
Just like for expressions, binary \ms{let}-statements and \ms{case}-statements need only the obvious
$\beta$ rule and binding rule, with all the interactions with other constructors derivable; these
rules are given in Figure~\ref{fig:ssa-reg-let2-case-expr}.

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{refl}}{\haslb{\Gamma}{r}{\ms{L}}}{\lbeq{\Gamma}{r}{r}{\ms{L}}} \qquad
    \prftree[r]{\rle{trans}}{\lbeq{\Gamma}{r}{s}{\ms{L}}}{\lbeq{\Gamma}{s}{t}{\ms{L}}}
      {\lbeq{\Gamma}{r}{t}{\ms{L}}} \qquad
    \prftree[r]{\rle{symm}}{\lbeq{\Gamma}{r}{s}{\ms{L}}}{\lbeq{\Gamma}{s}{r}{\ms{L}}}
    \\
    \prftree[r]{\rle{let}$_1$}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}
      {\lbeq{\Gamma, \bhyp{x}{A}}{r}{r'}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{x}{a}{r}}{\letstmt{x}{a'}{r'}}{\ms{L}}}
    \qquad
    \prftree[r]{\rle{let}$_2$}
      {\tmeq{\Gamma}{\epsilon}{e}{e'}{A \otimes B}}
      {\lbeq{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{r}{r'}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{(x, y)}{e}{r}}{\letstmt{(x, y)}{e'}{r'}}{\ms{L}}}
    \\
    \prftree[r]{\rle{case}}
      {\tmeq{\Gamma}{\epsilon}{e}{e'}{A + B}}
      {\lbeq{\Gamma, \bhyp{x}{A}}{r}{r'}{\ms{L}}}
      {\lbeq{\Gamma, \bhyp{y}{B}}{s}{s'}{\ms{L}}}
      {\lbeq{\Gamma}{\caseexpr{e}{x}{r}{y}{s}}{\caseexpr{e'}{x}{r'}{y}{s'}}{\ms{L}}}
    \\
    \prftree[r]{\rle{cfg}}
      {\lbeq{\Gamma}{r}{r'}{\ms{L}, (\lhyp{\ell_i}{A_i},)_i}}
      {\forall i. \lbeq{\Gamma, \bhyp{x_i}{A_i}}{t_i}{t_i'}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
      {\lbeq{\Gamma}
        {\where{r}{(\wbranch{\ell_i}{x_i: A_i}{t_i},)_i}}
        {\where{r'}{(\wbranch{\ell_i}{x_i: A_i}{t_i'},)_i}}
        {\ms{L}}
      }
    \\
    \prftree[r]{\rle{initial}}
      {\haslb{\Gamma}{r}{\ms{L}}}
      {\haslb{\Gamma}{s}{\ms{L}}}
      {\exists x, \Gamma\;x = \mb{0}}
      {\lbeq{\Gamma}{r}{s}{\ms{L}}}
  \end{gather*}
  \Description{}
  \caption{Congruence rules for \isotopessa regions}
  \label{fig:ssa-reg-congr-rules}
\end{figure}

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{let$_1$-$\beta$}}
      {\hasty{\Gamma}{\bot}{a}{A}}
      {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{x}{a}{r}}{[r/x]a}{\ms{L}}}
    \\
      \prftree[r]{\rle{let$_1$-op}}
      {\isop{f}{A}{B}{\epsilon}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\haslb{\Gamma, \bhyp{y}{B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{y}{f\;a}{r}}{\letstmt{x}{a}{\letstmt{y}{f\;x}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{let$_{1}$-let$_1$}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{B}}
      {\haslb{\Gamma, \bhyp{y}{B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{y}{(\letexpr{x}{a}{b})}{r}}{\letstmt{x}{a}{\letstmt{y}{b}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{let$_1$-pair}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\haslb{\Gamma, \bhyp{z}{A \otimes B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}
        {\letstmt{z}{(a, b)}{r}}
        {\letstmt{x}{a}{\letstmt{y}{b}{\letstmt{z}{(x, y)}{r}}}}
        {\ms{L}}}
    \\
    \prftree[r]{\rle{let$_{1}$-let$_2$}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{C}}
      {\haslb{\Gamma, \bhyp{z}{C}}{r}{\ms{L}}}
      {\lbeq{\Gamma}
        {\letstmt{z}{(\letexpr{(x, y)}{e}{c})}{r}}
        {\letstmt{(x, y)}{e}{\letstmt{z}{c}{r}}}
        {\ms{L}}}
    \\
    \prftree[r]{\rle{let$_1$-inl}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\haslb{\Gamma, \bhyp{y}{A + B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{y}{\linl{a}}{r}}{\letstmt{x}{a}{\letstmt{y}{\linl{x}}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{let$_1$-inr}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\haslb{\Gamma, \bhyp{y}{A + B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{y}{\linr{b}}{r}}{\letstmt{x}{b}{\letstmt{y}{\linr{x}}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{let$_1$-abort}}
      {\hasty{\Gamma}{\epsilon}{a}{\mb{0}}}
      {\haslb{\Gamma, \bhyp{y}{A}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{y}{\labort{a}}{r}}
        {\letstmt{x}{a}{\letstmt{y}{\labort{x}}{r}}}{\ms{L}}}
  \end{gather*}
  \Description{}
  \caption{Rewriting rules for \isotopessa unary \ms{let}-statements}
  \label{fig:ssa-reg-unary-let}
\end{figure}

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{let$_2$-pair}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\haslb{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{(x, y)}{(a, b)}{r}}{\letstmt{x}{a}{\letstmt{y}{b}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{let$_2$-bind}}
      {\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      {\haslb{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{r}{\ms{L}}}
      {\lbeq{\Gamma}{\letstmt{(x, y)}{e}{r}}{\letstmt{z}{e}{\letstmt{(x, y)}{z}{r}}}{\ms{L}}}
    \\
    \prftree[r]{\rle{case-inl}}
      {\hasty{\Gamma}{\epsilon}{a}{A}}
      {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      {\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}}}
      {\lbeq{\Gamma}{\caseexpr{\linl{a}}{x}{r}{y}{s}}{\letstmt{x}{a}{r}}{\ms{L}}}
    \\
    \prftree[r]{\rle{case-inr}}
      {\hasty{\Gamma}{\epsilon}{b}{B}}
      {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      {\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}}}
      {\lbeq{\Gamma}{\caseexpr{\linr{b}}{x}{r}{y}{s}}{\letstmt{y}{b}{s}}{\ms{L}}}
    \\
    \prftree[r]{\rle{case-bind}}
    {\hasty{\Gamma}{\epsilon}{e}{A + B}}
    {\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
    {\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}}}
    {\lbeq{\Gamma}{\caseexpr{e}{x}{r}{y}{s}}{\letstmt{z}{e}{\caseexpr{z}{x}{r}{y}{s}}}{\ms{L}}}
  \end{gather*}
  \Description{}
  \caption{Rewriting rules for \isotopessa binary \ms{let}-statements and \ms{case}-statements}
  \label{fig:ssa-reg-let2-case-expr}
\end{figure}

Dealing with \ms{where}-blocks, on the other hand, is a little bit more complicated, as shown by the
number of rules in Figure~\ref{fig:ssa-where-rules}. One difficulty is that, unlike the other region
constructors, we will need an $\eta$-rule as well as \emph{two} $\beta$-rules. The latter are simple
enough to state:
\begin{itemize}
  \item For $\ell_k$ defined in a \ms{where}-block, \brle{cfg-$\beta_1$} says that \todo{this}
  \item For $\kappa$ \emph{not} defined in a \ms{where}-block, \brle{cfg-$\beta_2$} says that
  \todo{this}
\end{itemize}
To state our $\eta$-rule, however, we will need to introduce some more machinery. Given a mapping
from a set of labels $\ell_i$ to associated regions $t_i$, we may define the \emph{control-flow
graph substitution} $\cfgsubst{(\wbranch{\ell_i}{x_i}{t_i},)_i}$ pointwise as follows:
\begin{equation}
  \cfgsubst{(\wbranch{\ell_i}{x_i}{t_i},)_i}\;\kappa\;a
  := (\where{\brb{\kappa}{a}}{(\wbranch{\ell_i}{x_i}{t_i},)_i})
\end{equation}

\TODO{text}

\begin{equation}
  \prftree[r]{\rle{cfgs}}
    {\forall i. \haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
    {\lbsubst{\Gamma}
      {\cfgsubst{(\wbranch{\ell_i}{x_i}{t_i},)_i}}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}{\ms{L}}}
\end{equation}

\TODO{text}

\begin{itemize}
  \item \todo{codiagonal, needs extensive explanation}
  \item \todo{uniformity, needs extensive explanation}
\end{itemize}

\begin{figure}
  \begin{gather*}
      \prftree[r]{\rle{cfg-$\beta_1$}}
        {\hasty{\Gamma}{\bot}{a}{A_k}}
        {\forall i. \haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
        {\lbeq{\Gamma}
          {\where{\brb{\ell_k}{a}}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}
          {\where{(\letstmt{x_k}{a}{t_k})}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}
          {\ms{L}}}
      \\
      \prftree[r]{\rle{cfg-$\beta_2$}}
        {\hasty{\Gamma}{\bot}{a}{A_k}}
        {\forall i. \haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
        {\kappa \notin \{(\ell_i,)_i\}}
        {\lbeq{\Gamma}
          {\where{\brb{\kappa}{a}}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}
          {\brb{\kappa}{a}}
          {\ms{L}}}
      \\
        \prftree[r]{\rle{cfg-$\eta$}}
        {\haslb{\Gamma}{r}{\ms{L}, (\lhyp{\ell_i}{A_i},)_i}}
        {\forall i. \haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
        {
          \lbeq{\Gamma}
            {\where{r}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}
            {[\cfgsubst{(\wbranch{\ell_i}{x_i}{t_i},)_i}]r}
            {\ms{L}}
        }
      \\
      % NOTE: in the development, it's (ret e) wseq s_0, not [e/x] s_0
      % but these are trivially equal by cfg-\beta_1
      \\
      \prftree[r]{\rle{uni}}
        {
          \prfStackPremises
          {\hasty{\Gamma, \bhyp{x}{A}}{\bot}{e}{B}}
          {\haslb{\Gamma}{r}{\ms{L}, \ell(A)}}
        }
        {
          \prfStackPremises
          {\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}, \kappa(B)}}
          {\haslb{\Gamma, \bhyp{x}{A}}{t}{\ms{L}, \ell(A)}}
        }
        {
          \lbeq{\Gamma, \bhyp{x}{A}}
            {[e/y]s}
            {\where{t}{\wbranch{\ell}{x}{\brb{\kappa}{e}}}}
            {\ms{L}, \kappa(B)}
        }
        {
          \lbeq{\Gamma}
            {\where{(\where{r}{\wbranch{\ell}{x}{\brb{\kappa}{e}}})}
              {\wbranch{\kappa}{y}{s}}}
            {\where{r}{t}}
            {\ms{L}}
        }
      \\
      \prftree[r]{\rle{codiag}}
        {\haslb{\Gamma}{r}{\ms{L}, \ell(A)}}
        {\haslb{\Gamma, \bhyp{y}{A}}{s}{\ms{L}, \ell(A), \kappa(A)}}
        {\lbeq{\Gamma}{\where{r}{\wbranch{\ell}{x}{\where{\brb{\kappa}{x}}
          {\wbranch{\kappa}{y}{s}}}}}
        {\where{r}{\wbranch{\ell}{y}{[\ell/\kappa]s}}}
        {\ms{L}}}
  \end{gather*}
  \Description{}
  \caption{Rewriting rules for \isotopessa \ms{where}-blocks}
  \label{fig:ssa-where-rules}
\end{figure}

\subsection{Metatheory}

We can now begin to investigate the metatheoretic properties of our equational theory. As a first
sanity check, we can verify that weakening, label-weakening, and loosening of effects all respect
our equivalence relation, as stated in the following lemma:
\begin{lemma}[Weakening (Rewriting)]
  Given $\Gamma \leq \Delta$, $\epsilon \leq \epsilon'$, we have that
  \begin{enumerate}[label=(\alph*)]
    \item $\tmeq{\Delta}{\epsilon}{a}{a'}{A} \implies \tmeq{\Gamma}{\epsilon'}{a}{a'}{A}$
    \item $\lbeq{\Delta}{r}{r'}{\ms{L}} \implies \lbeq{\Gamma}{r}{r'}{\ms{L}}$
    \item $\tmseq{\gamma}{\gamma'}{\Delta}{\Xi} 
      \implies \tmseq{\gamma}{\gamma'}{\Gamma}{\Xi}$ and
      $\tmseq{\gamma}{\gamma'}{\Xi}{\Gamma}\
      \implies \tmseq{\sigma}{\sigma'}{\Xi}{\Delta}$
    \item $\lbseq{\sigma}{\sigma'}{\Delta}{\ms{L}}{\ms{K}}
      \implies \lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}$
  \end{enumerate}
\end{lemma}
\begin{proof}
  By induction. \todo{formalization pointer?}
\end{proof}
In particular, note that this lemma uses an equivalence relation on substitutions and
label-substitutions: this is just the obvious pointwise extension of the equivalence relation on
terms and regions respectively. We give the rules for this relation in
Figure~\ref{fig:ssa-subst-equiv} in the interests of explicitness. It is straightforward to verify
that these are indeed equivalence relations.

\begin{figure}
  \begin{gather*}
    \prftree[r]{\rle{sb-nil}}{\tmseq{\cdot}{\cdot}{\Gamma}{\cdot}} \qquad
    \prftree[r]{\rle{sb-cons}}
      {\tmeq{\Gamma}{\epsilon}{a}{a'}{A}}{\tmseq{\gamma}{\gamma'}{\Gamma}{\Delta}}
      {\tmseq{\gamma, x \mapsto a}{\gamma', x \mapsto a'}{\Gamma}{\Delta, \thyp{x}{A}{\epsilon}}}
    \\
    \prftree[r]{\rle{sb-skip-l}}
      {\tmseq{\gamma}{\gamma'}{\Gamma}{\Delta}}
      {\tmseq{\gamma, x \mapsto a}{\gamma'}{\Gamma}{\Delta}} \qquad
    \prftree[r]{\rle{sb-skip-r}}
      {\tmseq{\gamma}{\gamma'}{\Gamma}{\Delta}}
      {\tmseq{\gamma}{\gamma', x \mapsto a'}{\Gamma}{\Delta}}
    \\
    \prftree[r]{\rle{ls-nil}}{\lbseq{\cdot}{\cdot}{\cdot}{\ms{K}}} \qquad
    \prftree[r]{\rle{ls-cons}}
      {\lbeq{\Gamma, \bhyp{x}{A}}{r}{r'}{\ms{K}}}
      {\lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}}
      {\lbseq
        {\sigma, \ell(x) \mapsto r}{\sigma', \ell(x) \mapsto r'}{\Gamma}
        {\ms{L}, \ell(A)}{\ms{K}}}
    \\
    \prftree[r]{\rle{ls-skip-l}}
      {\lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}}
      {\lbseq{\sigma, \ell(x) \mapsto r}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}}
      \qquad
    \prftree[r]{\rle{ls-skip-r}}
      {\lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}}
      {\lbseq{\sigma}{\sigma', \ell(x) \mapsto r'}{\Gamma}{\ms{L}}{\ms{K}}}
  \end{gather*}
  \Description{}
  \caption{Rules for the equivalence relation on \isotopessa substitutions and label-substitutions}
  \label{fig:ssa-subst-equiv}
\end{figure}

\TODO{lemma: substitution, composition is a congruence}

\begin{lemma}[Congruence (Substitution)]
  Given $\tmseq{\gamma}{\gamma'}{\Gamma}{\Delta}$, we have that
  \begin{enumerate}[label=(\alph*)]
    \item $\tmeq{\Delta}{\epsilon}{a}{a'}{A} 
      \implies \tmeq{\Gamma}{\epsilon}{[\gamma]a}{[\gamma']a'}{A}$
    \item $\lbeq{\Delta}{r}{r'}{\ms{L}} 
      \implies \lbeq{\Gamma}{[\gamma]r}{[\gamma']r'}{\ms{L}}$
    \item $\tmseq{\rho}{\rho'}{\Delta}{\Xi}
      \implies \tmseq{[\gamma]\rho}{[\gamma']\rho'}{\Gamma}{\Xi}$
    \item $\lbseq{\sigma}{\sigma'}{\Delta}{\ms{L}}{\ms{K}}
      \implies \lbseq{[\gamma]\sigma}{[\gamma']\sigma'}{\Gamma}{\ms{L}}{\ms{K}}$
  \end{enumerate}
\end{lemma}

\TODO{lemma: label-substitution, composition is a congruence}

\begin{lemma}[Congruence (Label Substitution)]
  Given $\lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}}$, we have that
  \begin{enumerate}[label=(\alph*)]
    \item $\lbeq{\Gamma}{r}{r'}{\ms{L}} \implies \lbeq{\Gamma}{[\sigma]r}{[\sigma']r'}{\ms{K}}$
    \item $\lbseq{\kappa}{\kappa'}{\Gamma}{\ms{L}}{\ms{J}}
      \implies \lbseq{[\sigma]\kappa}{[\sigma']\kappa'}{\Gamma}{\ms{K}}{\ms{J}}$
  \end{enumerate}
\end{lemma}

\section{Denotational Semantics}

\subsection{Freyd Elgot Categories}

\TODO{rework, expand, and fold in...}

\citet{moggi-91-monad} showed that the Kleisli category of a strong monad over a CCC interprets
effectful higher-order functional programs. We are faced, however, with two problems. On one hand,
SSA has features not necessarily supported by such models. In particular, while distributive
coproducts are sufficient to model terminating control-flow, SSA models programs with arbitrary,
unstructured cyclic control-flow. On the other hand, SSA, is only a first-order language. In
particular, since SSA does not support first-class functions, we have no need for a cartesian
closure. Similarly, first-class computations, represented by objects of the form
$\ms{T}(\ms{T}(A))$, are not usually supported by SSA.

Given that we want to model SSA with some category $\mc{C}$, we hence have to think about what
structure we need $\mc{C}$ to possess so that it has all our desired features, but no more.
Obviously, we need a way to take the product of two objects, to be able to model contexts as well as
pairs. The usual way to do this is via \emph{monoidal categories}. These, however, have too many
equations: in a monoidal category, computations operating on independent data must always commute
(this is the ``sliding rule''), which is obviously not true for effects such as printing, since
$$
\ms{print}(x) ; \ms{print}(y) \neq \ms{print}(y) ; \ms{print}(x)
$$
Instead, we will only require that our category is \emph{premonoidal}: ``monoidal, without
sliding.'' Indeed, the Kleisli category of a strong monad on a CCC is not always monoidal, as
demonstrated by the writer monad on $\ms{Set}$ (which exposes $\ms{print}$), but \emph{is} always
premonoidal. We define a premonoidal category as follows:
\begin{definition}[Symmetric Premonoidal Category]
  We define a \emph{binoidal category} to be a category $\mc{C}$ equipped with a binary operation
  $\otimes : |\mc{C}| \times |\mc{C}| \to |\mc{C}|$ on the objects of $\mc{C}$ and, for each $A, B
  \in |\mc{C}|$, functors $A \otimes -, - \otimes B : \mc{C} \to \mc{C}$. We say a morphism $f : A
  \to A'$ in a binoidal category is \emph{central} if, for all $g : B \to B'$, it satisfies
  \emph{sliding}:
  $$
  f \otimes B ; A' \otimes g = A \otimes g ; f \otimes B' \qquad
  B \otimes f ; g \otimes A' = g \otimes A ; B' \otimes f
  $$
  in which case we may write these morphisms as $f \otimes g : A \otimes B \to A' \otimes B'$ and $g
  \otimes f : B \otimes A \to B' \otimes A'$ respectively. A \emph{premonoidal category} is, then, a
  binoidal category equipped with:
  \begin{itemize}
    \item An \emph{identity} object $I \in |\mc{C}|$
    \item For each triple of objects $A, B, C \in |\mc{C}|$, a central, natural isomorphism
    $\alpha_{A, B, C} : (A \otimes B) \otimes C \to A \otimes (B \otimes C)$, the \emph{associator}
    \item For each object $A$, central, natural isomorphisms $\lambda_A : A \otimes I \to A$ and
    $\rho_A : I \otimes A \to A$, the \emph{left} and \emph{right unitors}
  \end{itemize}
  satisfying the \emph{triangle} and \emph{pentagon identity}
  $$
  \alpha_{A, I, B} ; A \otimes \lambda_B = \rho_A \otimes B \qquad
  \alpha_{A \otimes B, C, D} ; \alpha_{A, B, C \otimes D}
  = \alpha_{A, B, C} \otimes D ; \alpha_{A, B \otimes C, D} ; A \otimes \alpha_{A, B, C}
  $$
  We say a premonoidal category is \emph{symmetric} if it is also equipped with a central, natural
  involution $\sigma_{A, B} : A \otimes B \to B \otimes A$, the \textit{symmetry}, satisfying the
  \emph{hexagon identity}
  $$
  \alpha_{A, B, C} ; \sigma_{A, B \otimes C} ; \alpha_{B, C, A}
  = \sigma_{A, B} \otimes C ; \alpha_{B, A, C} ; B \otimes \sigma_{A, C}
  $$
  We say a premonoidal category is \emph{monoidal} if every morphism is central.
\end{definition}
Just like for higher-order functional languages, we can interpret types $A$ as objects $\dnt{A} :
|\mc{C}|$. Similarly, we can interpret variable contexts $\Gamma$ by taking products of objects, as
follows:
$$
\boxed{\dnt{\Gamma} : |\mc{C}|} \qquad 
  \dnt{\cdot} = I \qquad \dnt{\Gamma, \bhyp{x}{A}} = \dnt{\Gamma} \otimes \dnt{A}
$$
We would like to interpret a expression-in-context $\hasty{\Gamma}{\epsilon}{a}{A}$ as a morphism in
$\mc{C}$ from $\dnt{\Gamma}$ to $\dnt{A}$. However, in standard SSA, it is possible for a variable
to be unused, or used multiple times. Our premonoidal structure, however, does not give us any way
to \emph{project} out of a product type, making it impossible to interpet expressions-in-context
like
$
\hasty{\bhyp{x}{A}, \bhyp{y}{B}}{}{x}{A}
$. 
Indeed, a premonoidal category can only interpret \emph{linear} expressions, that is, those which
use every variable exactly once. To rectify this, much like how the CCC underlying a strong monad's
Kleisli category allows us to perform variable manipulation, when viewed as a subcategory (through
inclusion via the monad's unit), we can postulate a subcategory $\mc{C}_\bot \subseteq \mc{C}$
equipped with only a \emph{cartesian}, rather than \emph{cartesian closed}, structure (since we do
not want to require support for first-class functions or computations); this is called a \emph{Freyd
category}, and is defined as follows: \TODO{cite original paper for Freyd categories?}
\begin{definition}[Freyd category]
  A \emph{Freyd category} is a premonoidal category $\mc{C}$ equipped with a wide subcategory
  $\mc{C}_\bot \subseteq \mc{C}$ of \emph{pure} morphisms such that
  \begin{itemize}
    \item $\mc{C}_\bot$ contains all associators, unitors, and symmetries
    \item $I$ is a terminal object in $\mc{C}_\bot$
    \item For each $A, B$, $A \otimes B$ is a cartesian product of $A, B$ in $\mc{C}_\bot$
    \item For pure morphisms $f, g$, $f \otimes g = \langle \pi_l; f, \pi_r ; g  \rangle$
  \end{itemize}
  Alternatively, it is equivalent to require
  \begin{itemize}
    \item $\mc{C}_\bot$ contains all associators, unitors, and symmetries
    \item $I$ is a terminal object in $\mc{C}_\bot$
    \item For each $A$, there exists a pure morphism $\dmor{A} : A \to A \otimes A$ forming a
          comonoid with the terminal morphism $\tmor{A} : A \to I$, i.e: $\dmor{A} ; \tmor{A}
          \otimes A ; \rho = \dmor{A} ; A \otimes \tmor {A} ; \lambda = \ms{id}_A$
    \item For every pure morphism $f : A \to_\bot B$, $f ; \dmor{B} = \dmor{A} ; f \otimes f$
  \end{itemize}
  In both cases, we have that $\pi_l = A \otimes \tmor{B} ; \lambda$, $\pi_r = \tmor{A}
  \otimes B ; \rho$, $\langle f, g \rangle = \dmor{A} ; f \otimes g$, and $\dmor{A} = \langle
  \ms{id}_A, \ms{id}_A \rangle$
\end{definition}
We now have everything we need to model effectful first-order expressions. For reasoning about
substitution, we will also demand that the denotation of ``\emph{pure}" expressions
$\hasty{\Gamma}{\bot}{a}{A}$ lies in $\mc{C}_\bot(\dnt{\Gamma}, \dnt{A})$; in general, we will write
morphisms in $\mc{C}_\bot$ as $A \to_\bot B$.

At this point, we still have no way to interpret control-flow, i.e. $\ms{case}$-expressions.
Furthermore, if we want to model regions as morphisms, we need some way of modeling label-contexts
$\ms{L}$. At first glance, it seems sufficient for branching control-flow to require the existence
of coproducts, and indeed, assuming the existence of all coproducts and an initial object, we may
model label-contexts as follows:
$$
\boxed{\dnt{\ms{L}} : |\mc{C}|} \qquad 
  \dnt{\cdot} = \mb{0} \qquad \dnt{\ms{L}, \lhyp{\ell}{A}} = \dnt{\ms{L}} + \dnt{A}
$$
Regions can now be interpreted as morphisms in $\mc{C}$ from $\dnt{\Gamma}$ to $\dnt{\ms{L}}$, as
desired. However, it turns out that our coproducts must be \emph{distributive} to allow us to use
variables in scope before the branch. In particular, we define a \emph{distributive} premonoidal
category as follows:
\begin{definition}[Distributive category]
  A premonoidal category $\mc{C}$ with all coproducts is \emph{distributive} if, for all $A, B, C$,
  the obvious morphism
  $$
  \delta_{A, B, C} 
    = [(A + \iota_l), (A + \iota_r)] : (A \otimes B) + (A \otimes C) \to A \otimes (B + C)
  $$
  has an inverse.
\end{definition}
We note in particular that every CCC with coproducts is distributive. The last piece of the puzzle,
allowing us to model loops in regions, is the existence of an \emph{Elgot structure}. We would also
like our Elgot structure to be \emph{strong}; that is, compatible with the distributor, so that we
can soundly shuttle access variables in scope in the loop body. Formally, we define a \emph{(strong)
Elgot structure} as follows:
\begin{definition}[(Strong) Elgot structure]
  A category $\mc{C}$ with all coproducts is said to have an \emph{Elgot structure} if we can define
  an operator $(-)^\dagger$ taking every morphism $f : A \to B + A$ to a morphism $f^\dagger : A \to
  B$, the \emph{fixpoint} of $f$, satisfying the following axioms:
  \begin{itemize}
    \item \emph{Fixpoint:} $\forall f : A \to B + A, f^\dagger = f;[\ms{id}, f^\dagger]$
    \item \emph{Naturality:} $\forall f : A \to B + A, \forall g : B \to C, 
      (f;g + \ms{id})^\dagger = f^\dagger;g : A \to C$
    \item \emph{Codiagonal:} $\forall f : A \to (B + A) + A, 
      (f^\dagger)^\dagger = (f;[\ms{id}, \iota_r])^\dagger : A \to B$
    \item \emph{Uniformity:} 
    $
      \forall f : A' \to B + A', \forall g : A \to B + A \forall h : A \to A', 
        h;f = g;\ms{id} + h \implies h;f^\dagger = g^\dagger
    $
  \end{itemize}
  If $\mc{C}$ is distributive, we say it has a \emph{strong Elgot structure} if
  $
  \forall f: A \to B + A, (f \otimes C ; \delta^{-1})^\dagger = f^\dagger \otimes C
  $
  In particular, we say a monad is Elgot if its Kliesli category has an Elgot structure. Similarly,
  we say a \emph{strong} monad is strong Elgot if its Kliesli category has a strong Elgot structure.
\end{definition}

\TODO{discuss string diagrams? string diagrammatic proofs?}

\subsection{Semantics}

We now have all the ingredients we need to give a semantics to \isotopessa expressions and regions.
In particular, an \isotopessa model consists of:
\begin{itemize}
  \item A distributive premonoidal category $\mc{C}$, equipped with an Elgot structure
  \item A complete lattice $E$, and a continuous function $\epsilon \mapsto \mc{C}_\epsilon$ from
  $E$ to wide subcategories of $\mc{C}$, such that $\mc{C}_\top = \mc{C}$, and $(\mc{C}, \mc{V} =
  \mc{C}_\bot)$ is a Freyd category.
\end{itemize}
We will write morphisms $\mc{C}_\epsilon(A, B)$ as $A \to_\epsilon B$, and morphisms $\mc{C}(A, B)$
as $A \to B$. Note that, whenever $\mc{C}$ is a distributive Elgot Freyd category, we can trivially
obtain an \isotopessa model by choosing $E = \{\top, \bot\}$; hence, this re-framing does not add
any additional generality, but simplifies bookkeeping. We may also choose $E = \{*\}$ if and only if
$\mc{C}$ is in fact Cartesian.

\TODO{we model types in the obvious manner; as in Figure \ref{fig:ssa-ty-sem}}

\begin{figure}
  \begin{align*}
    \boxed{\dnt{A} : |\mc{C}|} \qquad 
    & \dnt{\mb{1}} = I \qquad
      \dnt{A \otimes B} = \dnt{A} \otimes \dnt{B} \qquad
      \dnt{\mb{0}} = \mb{0} \qquad
      \dnt{A + B} = \dnt{A} + \dnt{B} \qquad \\
    \boxed{\dnt{\Gamma} : |\mc{C}|} \qquad
    & \dnt{\cdot} = I \qquad
      \dnt{\Gamma, \thyp{x}{A}{\epsilon}} = \dnt{\Gamma} \otimes \dnt{A} \\
    \boxed{\dnt{\ms{L}} : |\mc{C}|} \qquad
    & \dnt{\cdot} = 0 \qquad
      \dnt{\ms{L}, \lhyp{\ell}{A}} = \dnt{\ms{L}} + \dnt{A} \\
  \end{align*}
  \begin{equation*}
    \boxed{\dnt{\Gamma \leq \Delta} : \dnt{\Gamma} \to_\bot \dnt{\Delta}}
  \end{equation*}
  \begin{gather*}
    \dnt{\cdot \leq \cdot} = \ms{id}_I \qquad
    \dnt{\Gamma, \thyp{x}{A}{\epsilon} \leq \Delta} = \pi_l;\dnt{\Gamma \leq \Delta} \qquad
    \dnt{\Gamma, \thyp{x}{A}{\epsilon} \leq \Delta, \thyp{x}{A}{\epsilon}}
    = \dnt{\Gamma \leq \Delta} \otimes \dnt{A} \\ \\
  \end{gather*}
  \begin{equation*}
    \boxed{\dnt{\ms{L} \leq \ms{K}} : \dnt{\ms{L}} \to_\bot \dnt{\ms{K}}}
  \end{equation*}
  \begin{gather*}
    \dnt{\cdot \leq \cdot} = \ms{id}_{\mb{0}} \qquad
    \dnt{\ms{L} \leq \ms{K}, \lhyp{\ell}{A}} = \dnt{\ms{L} \leq \ms{K}};\iota_\ell \qquad
    \dnt{\ms{L}, \lhyp{\ell}{A} \leq \ms{K}, \lhyp{\ell}{A}}
    = \dnt{\ms{L} \leq \ms{K}} + \dnt{A}
  \end{gather*}
  \caption{Denotational semantics for \isotopessa types, contexts, and weakenings}
  \Description{}
  \label{fig:ssa-ty-sem}
\end{figure}

\TODO{expressions are modeled as morphisms in the obvious manner; we also have that denotations with
different effects are equal}

\begin{figure}
  \begin{equation*}
    \boxed{\dnt{\hasty{\Gamma}{\epsilon}{a}{A}} : \dnt{\Gamma} \to_\epsilon \dnt{A}}
  \end{equation*}
  \begin{align*}
    \dnt{\hasty{\Gamma}{\epsilon}{x}{A}} &= \pi_{\Gamma, x} \\
    \dnt{\hasty{\Gamma}{\epsilon}{f\;a}{B}} 
      &= \dnt{\hasty{\Gamma}{\epsilon}{a}{A}} ; \dnt{\isop{f}{A}{B}{\epsilon}} \\
    \dnt{\hasty{\Gamma}{\epsilon}{\letexpr{x}{a}{b}}{B}}
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\hasty{\Gamma}{\epsilon}{a}{A}};
      \\&\quad\; 
      \dnt{\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{b}{B}}
      \\
    \dnt{\hasty{\Gamma}{\epsilon}{(a, b)}{A \otimes B}} 
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\hasty{\Gamma}{\epsilon}{a}{A}} \ltimes \dnt{\hasty{\Gamma}{\epsilon}{b}{B}}
      % ; \dnt{\hasty{\Gamma}{\epsilon}{a}{A}} \otimes \dnt{\Gamma} 
      % ; \dnt{A} \otimes \dnt{\hasty{\Gamma}{\epsilon}{b}{B}}
      \\
    \dnt{\hasty{\Gamma}{\epsilon}{\letexpr{(x, y)}{e}{c}}{C}}
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\hasty{\Gamma}{\epsilon}{e}{A \otimes B}} ;
      \\&\quad\; 
      \dnt{\hasty{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{\epsilon}{c}{C}}
      \\
    \dnt{\hasty{\Gamma}{\epsilon}{()}{\mb{1}}} &= 1_{\dnt{\Gamma}} \\
    \dnt{\hasty{\Gamma}{\epsilon}{\linl{a}}{A + B}}
      &= \dnt{\hasty{\Gamma}{\epsilon}{a}{A}} ; \iota_l \\
    \dnt{\hasty{\Gamma}{\epsilon}{\linr{b}}{A + B}}
      &= \dnt{\hasty{\Gamma}{\epsilon}{b}{B}} ; \iota_r \\
    \dnt{\hasty{\Gamma}{\epsilon}{\caseexpr{e}{x}{a}{y}{b}}{C}}
      &= \dnt{\hasty{\Gamma}{\epsilon}{e}{A + B}}
      ; \\& \quad\; 
      \dnt{\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{a}{A}}
      + \dnt{\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{b}{B}}
      \\
    \dnt{\hasty{\Gamma}{\epsilon}{\labort{a}}{A}} 
      &= \dnt{\hasty{\Gamma}{\epsilon}{a}{\mb{0}}} ; 0_{\dnt{A}}
  \end{align*}
  \caption{Denotational semantics for \isotopessa expressions}
  \Description{Denotational semantics for isotope-SSA expressions}
  \label{fig:ssa-expr-sem}
\end{figure}

\TODO{regions are similarly modeled as morphisms in the obvious manner}

\TODO{note on how Elgot structure is like Bohm-Jacopini for conversion to structured control-flow}

\begin{figure}
  \begin{equation*}
    \boxed{\dnt{\haslb{\Gamma}{r}{\ms{L}}} : \dnt{\Gamma} \to \dnt{\ms{L}}}
  \end{equation*}
  \begin{align*}
    \dnt{\haslb{\Gamma}{\brb{\ell}{a}}{\ms{L}}} 
      &= \dnt{\hasty{\Gamma}{\bot}{a}{A}} ; \iota_{\ms{L}, \ell}
      \\
    \dnt{\haslb{\Gamma}{\letstmt{x}{a}{r}}{\ms{L}}}
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\hasty{\Gamma}{\epsilon}{a}{A}}
      ; \dnt{\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}} 
      \\
    \dnt{\haslb{\Gamma}{\letstmt{(x, y)}{e}{r}}{\ms{L}}}
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\hasty{\Gamma}{\epsilon}{e}{A \otimes B}}
      ; \dnt{\haslb{\Gamma, \bhyp{x}{A}, \bhyp{y}{B}}{r}{\ms{L}}} 
      \\ 
    \dnt{\haslb{\Gamma}{\casestmt{e}{x}{r}{y}{s}}{\ms{L}}}
      &= \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\hasty{\Gamma}{\epsilon}{e}{A + B}}
      ; \delta^{-1} ;
      \\&\quad\;
      \dnt{\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{L}}}
      + \dnt{\haslb{\Gamma, \bhyp{y}{B}}{s}{\ms{L}}}
      \\
    \dnt{\haslb{\Gamma}{\where{r}{(\wbranch{\ell_i}{x_i}{t_i},)_i}}{\ms{L}}}
      &=  
      \Delta_{\dnt{\Gamma}}
      ; \dnt{\Gamma} \otimes \dnt{\haslb{\Gamma}{r}{\ms{L}, (\lhyp{\ell_i}{A_i},)_i}} 
      ; \delta^{-1} ;
      \alpha^+_{}
      \\ &\quad\;
      (
        \Sigma_i (\Delta_{\dnt{\Gamma}} 
          ; \dnt{\Gamma} \otimes 
            \dnt{\haslb{\Gamma, \bhyp{x_i}{A_i}}{t_i}{\ms{L}, (\lhyp{\ell_j}{A_j},)_j}}
          ; 
          )
      )^\dagger
  \end{align*}
  \caption{Denotational semantics for \isotopessa regions}
  \Description{Denotational semantics for isotope-SSA regions}
  \label{fig:ssa-reg-sem}
\end{figure}

\TODO{weakenings are modeled as projections, label-weakenings as injections}

\TODO{text for weakening lemma}

\begin{lemma}[(Label) Weakening]
  Given $\Gamma \leq \Gamma'$ and $\ms{L}' \leq \ms{L}$, $\ms{K}' \leq \ms{K}$, we have
  \begin{enumerate}[label=(\alph*)]
    \item $\dnt{\Gamma \leq \Delta} = \dnt{\Gamma \leq \Gamma'};\dnt{\Gamma' \leq \Delta}$
    \item $\dnt{\ms{L}' \leq \ms{K}} = \dnt{\ms{L}' \leq \ms{L}};\dnt{\ms{L} \leq \ms{K}}$
    \item $\dnt{\hasty{\Gamma}{\epsilon}{a}{A}} 
      = \dnt{\Gamma \leq \Gamma'};\dnt{\hasty{\Gamma'}{\epsilon}{a}{A}}$
    \item $\dnt{\haslb{\Gamma}{r}{\ms{L}}}
      = \dnt{\Gamma \leq \Gamma'}
      ; \dnt{\haslb{\Gamma'}{r}{\ms{L}'}}
      ; \dnt{\ms{L}' \leq \ms{L}}$
    \item $\dnt{\issubst{\gamma}{\Gamma}{\Delta}}
      = \dnt{\Gamma \leq \Gamma'};\dnt{\issubst{\gamma}{\Gamma'}{\Delta}}$
    \item $\dnt{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}
      = \dnt{\Gamma \leq \Gamma'} \otimes \dnt{\ms{L}}
      ; \dnt{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}'}}
      ; \dnt{\ms{K}' \leq \ms{K}}
      $
  \end{enumerate}
\end{lemma}

\TODO{(label) substitutions are modeled as morphisms}

\TODO{not always pure! but pure when all target variables are, and sometimes other times!}

\begin{figure}
  \begin{equation*}
    \boxed{\dnt{\issubst{\gamma}{\Gamma}{\Delta}} 
      : \dnt{\Gamma} \to \dnt{\Delta}}
  \end{equation*}
  \begin{gather*}
    \dnt{\issubst{\cdot}{\Gamma}{\cdot}} = \tmor{\dnt{\Gamma}}
    \qquad
    \dnt{\issubst{\gamma, x \mapsto e}{\Gamma}{\Delta}} 
    = \dnt{\issubst{\gamma}{\Gamma}{\Delta}}
    \\
    \dnt{\issubst{\gamma, x \mapsto e}{\Gamma}{\Delta, \thyp{x}{A}{\epsilon}}}
    = \dmor{\dnt{\Gamma}};\dnt{\issubst{\gamma}{\Gamma}{\Delta}}
  \end{gather*}
  \begin{equation*}
    \boxed{\dnt{\lbsubst{\Gamma}{\kappa}{\ms{L}}{\ms{K}}} 
      : \dnt{\Gamma} \otimes \dnt{\ms{L}} \to \dnt{\ms{K}}}
  \end{equation*}
  \begin{gather*}
    \dnt{\lbsubst{\cdot}{\Gamma}{\cdot}{\ms{K}}} 
      = \tmor{\dnt{\Gamma} \otimes \mb{1}};0_{\ms{K}} \qquad
    \dnt{\lbsubst{\kappa, \ell(x) \mapsto r}{\Gamma}{\ms{L}}{\ms{K}}}
      = \dnt{\lbsubst{\kappa}{\Gamma}{\ms{L}}{\ms{K}}}
    \\
    \dnt{\lbsubst{\kappa, \ell(x) \mapsto r}{\Gamma}{\ms{L}, \ell(A)}{\ms{K}}}
      = [
        \dnt{\lbsubst{\kappa}{\Gamma}{\ms{L}}{\ms{K}}}, 
        \dnt{\haslb{\Gamma, \bhyp{x}{A}}{r}{\ms{K}}}
      ]
  \end{gather*}
  \caption{Denotational semantics for \isotopessa (label) substitutions}
  \Description{}
  \label{fig:ssa-vsubst-sem} 
\end{figure}

\subsection{Rewriting and Substitution}

\TODO{most simple substitution theorem is \emph{rewriting}:}

\begin{theorem}[Soundness (Rewriting)]
  Given substitutions $\issubst{\gamma, \gamma'}{\Gamma}{\Delta}$ such that, for all 
  $\thyp{x}{A}{\epsilon} \in \Delta$, $\dnt{\hasty{\Gamma}{\epsilon}{\gamma\;x}{A}} =
  \dnt{\hasty{\Gamma}{\epsilon}{\gamma'\;x}{A}}$, we have
  \begin{enumerate}[label=(\alph*)]
    \item Given $\hasty{\Delta}{\epsilon}{a}{A}$, 
      $\dnt{\hasty{\Gamma}{\epsilon}{[\gamma]a}{A}} = \dnt{\hasty{\Gamma}{\epsilon}{[\gamma']a}{A}}$
    \item Given $\issubst{\rho}{\Delta}{\Xi}$, $\dnt{\issubst{[\gamma]\rho}{\Gamma}{\Xi}} =
      \dnt{\issubst{[\gamma']\rho}{\Gamma}{\Xi}}$
    \item Given $\haslb{\Delta}{r}{\ms{L}}$, $\dnt{\haslb{\Gamma}{[\gamma]r}{\ms{L}}} =
      \dnt{\haslb{\Gamma}{[\gamma']r}{\ms{L}}}$
    \item Given $\lbsubst{\rho}{\Delta}{\ms{L}}{\ms{K}}$,
      $\dnt{\lbsubst{\Gamma}{[\gamma]\rho}{\ms{L}}{\ms{K}}} =
      \dnt{\lbsubst{\Gamma}{[\gamma']\rho}{\ms{L}}{\ms{K}}}$ 
  \end{enumerate}
\end{theorem}

\TODO{if our substitution \emph{is} pure, we can also prove that substitution is \emph{sound}:}

\begin{theorem}[Soundness (Substitution)]
  Given $\dnt{\issubst{\gamma}{\Gamma}{\Delta}} : \dnt{\Gamma} \to_\bot
  \dnt{\Delta}$ (in particular, this is always the case when \todo{the effect
  of $\Delta$ is $\bot$, but write this down}, we have that
  \begin{enumerate}[label=(\alph*)]
    \item $\dnt{\hasty{\Gamma}{\epsilon}{[\gamma]a}{A}} 
      = \dnt{\issubst{\gamma}{\Gamma}{\Delta}};\dnt{\hasty{\Delta}{\epsilon}{a}{A}}$
    \item $\dnt{\haslb{\Gamma}{[\gamma]r}{\ms{L}}}
      = \dnt{\issubst{\gamma}{\Gamma}{\Delta}};\dnt{\haslb{\Delta}{r}{\ms{L}}}$
    \item $\dnt{\issubst{[\gamma]\rho}{\Delta}{\Xi}}
      = \dnt{\issubst{\gamma}{\Gamma}{\Delta}};\dnt{\issubst{\rho}{\Delta}{\Xi}}$
    \item $\dnt{\lbsubst{\Gamma}{[\gamma]\sigma}{\ms{L}}{\ms{K}}}
      = \dnt{\issubst{\gamma}{\Gamma}{\Delta}};\dnt{\lbsubst{\Delta}{\sigma}{\ms{L}}{\ms{K}}}$
  \end{enumerate}
\end{theorem}

\TODO{note that soundness $\implies$ rewriting, but rewriting works for \emph{all} substitutions
(including impure ones), whereas soundness is only for pure substitutions!}

\TODO{On the other hand, \emph{all} label substitutions are sound:}

\begin{theorem}[Soundness (Label Substitution)]
  Given $\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}$, we have
  \begin{enumerate}[label=(\alph*)]
    \item $\dnt{\haslb{\Gamma}{[\sigma]r}{\ms{K}}}
      = \dmor{\dnt{\Gamma}}
      ;\dnt{\Gamma} \otimes \dnt{\haslb{\Gamma}{r}{\ms{L}}}
      ;\dnt{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}$
    \item $\dnt{\lbsubst{\Gamma}{[\sigma]\sigma'}{\ms{M}}{\ms{K}}}
      = \dmor{\dnt{\Gamma}} \otimes \dnt{\ms{L}} ; \alpha
      ; \dnt{\Gamma} \otimes \dnt{\lbsubst{\Gamma}{\sigma'}{\ms{M}}{\ms{L}}}
      ; \dnt{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}}$
  \end{enumerate}
\end{theorem}

\TODO{text}

\subsection{Equational Theory}

\TODO{text}

\begin{theorem}[Soundness (Equational Theory)]
  We have that
  \begin{enumerate}[label=(\alph*)]
    \item $\tmeq{\Gamma}{\epsilon}{a}{a'}{A} \implies 
      \dnt{\hasty{\Gamma}{\epsilon}{a}{A}} = \dnt{\hasty{\Gamma}{\epsilon}{a'}{A}}$
    \item $\lbeq{\Gamma}{r}{r'}{\ms{L}} \implies
      \dnt{\haslb{\Gamma}{r}{\ms{L}}} = \dnt{\haslb{\Gamma}{r'}{\ms{L}}}$
    \item $\tmseq{\gamma}{\gamma'}{\Gamma}{\Delta} \implies
      \dnt{\issubst{\gamma}{\Gamma}{\Delta}} = \dnt{\issubst{\gamma'}{\Gamma}{\Delta}}$
    \item $\lbseq{\sigma}{\sigma'}{\Gamma}{\ms{L}}{\ms{K}} \implies
      \dnt{\lbsubst{\Gamma}{\sigma}{\ms{L}}{\ms{K}}} 
      = \dnt{\lbsubst{\Gamma}{\sigma'}{\ms{L}}{\ms{K}}}$
  \end{enumerate}
\end{theorem}

\TODO{text; diagram for each rule?}

\subsection{Completeness}

\label{ssec:completeness}

\TODO{text}

\begin{theorem}[Completeness (Expressions)]
  The category $\ms{Th}^\otimes(\Gamma)$ with
  \begin{itemize}
    \item Objects types $A, B, C$
    \item Morphisms $\ms{Th}^\otimes(\Gamma)(A, B) 
      = \bigcup_\epsilon\ms{Th}^\otimes(\Gamma)_\epsilon(A, B) 
      = \bigcup_\epsilon\{e \mid \hasty{\Gamma, \bhyp{\invar}{A}}{\epsilon}{e}{A}\}$
      quotiented by $\tmeq{\Gamma, \bhyp{\invar}{A}}{}{e}{e'}{A}$
      % TODO: epsilation lore
    \item Identity $\hasty{\Gamma, \bhyp{\invar}{A}}{\bot}{\invar}{A}$
    \item Composition $e;e' = (\ms{let}\;\invar = e; e')$ 
  \end{itemize} 
  is a distributive Freyd category, with:
  \begin{itemize}
    \item Pure morphisms generated by, given $\hasty{\Gamma, \bhyp{\invar}{A}}{\epsilon}{e}{B}$ and
          $\haslb{\Gamma, \bhyp{\invar}{A}}{\ms{ret}\;e}{B, \ms{L}}$
    \item Tensor functors 
      $- \otimes X : e \mapsto \ms{let}\;(\invar, x) 
        = \invar; (e ; (\invar, x))$
      and 
      $X \otimes - : e \mapsto \ms{let}\;(x, \invar) 
      = \invar; (e ; (x, \invar))$
    \item Projections $\ms{let}\;(x, y) = \invar; x$ and  
      $\ms{let}\;(x, y) = \invar; y$
    \item Diagonal: $(\invar, \invar)$
    \item Injections: $\ms{inl}\;\invar$, $\ms{inr}\;\invar$
    \item Sums: $
      [a, b] = \caseexpr{\invar}{\invar}{a}{\invar}{b}
    $
    \item Distributor
      $\delta = \caseexpr{\invar}{(x, y)}{(x, \ms{inl}\;y)}{(x, y)}{(x, \ms{inr}\;y)}$
      with inverse
      $\delta^{-1} = \ms{let}\;(x, y) = \invar; 
        \caseexpr{y}{z}{\ms{inl}(x, z)}{z}{\ms{inr}(x, z)}$
  \end{itemize}
  % In particular, taking $\ms{Th}(\cdot)$ as our model, we have 
  % $
  %   \tmeq{\Gamma}{\epsilon}{e}{e'}{A} 
  %   \iff \dnt{\hasty{\Gamma}{\epsilon}{e}{A}} = \dnt{\hasty{\Gamma}{\epsilon}{e'}{A}}
  % $
\end{theorem}

\TODO{text}

\begin{theorem}[Completeness (Regions)]
  The category $\ms{Th}(\Gamma, \ms{L})$ with
  \begin{itemize}
    \item Objects types $A, B, C$
    \item Morphisms $\ms{Th}(\Gamma, \ms{L})(A, B) 
      = \{r \mid \haslb{\Gamma, \bhyp{\invar}{A}}{r}{\ms{L}, \ms{ret}(B)}\}$ quotiented by
      $\lbeq{\Gamma, \bhyp{\invar}{A}}{r}{r'}{\ms{L}, \ms{ret}(B)}$
    \item Identity $\haslb{\Gamma, \bhyp{\invar}{A}}{\ms{br}\;\ms{ret}\;\invar}{\ms{L}, \ms{ret}(A)}$
    \item Composition $r;r' = [\ms{id}, \ms{ret}(\invar) \mapsto r']r$ 
  \end{itemize}
  is a distributive Freyd category with:
  \begin{itemize}
    \item Pure morphisms generated by, given $\hasty{\Gamma, \bhyp{\invar}{A}}{\epsilon}{e}{B}$ and
          $\haslb{\Gamma, \bhyp{\invar}{A}}{\ms{ret}\;e}{B, \ms{L}}$
    \item Tensor functors 
      $- \otimes X : r \mapsto \ms{let}\;(\invar, x) 
        = \invar; (r ; \ms{ret}\;(\invar, x))$
      and 
      $X \otimes - : r \mapsto \ms{let}\;(x, \invar) 
      = \invar; (r ; \ms{ret}\;(x, \invar))$
    \item Projections $\ms{let}\;(x, y) = \invar; \ms{ret}\;x$ and  
      $\ms{let}\;(x, y) = \invar; \ms{ret}\;y$
    \item Diagonal: $\ms{ret}\;(\invar, \invar)$
    \item Injections: $\ms{ret}\;\ms{inl}\;\invar$, $\ms{ret}\;\ms{inr}\;\invar$
    \item Sums: $
      [r, r'] = \casestmt{\invar}{\invar}{r}{\invar}{r'}
    $
    \item Distributor
      $\delta = \casestmt{\invar}{(x, y)}{\ms{ret}\;(x, \ms{inl}\;y)}{(x, y)}{\ms{ret}\;(x, \ms{inr}\;y)}$
      with inverse
      $\delta^{-1} = \ms{let}\;(x, y) = \invar; 
        \casestmt{y}{z}{\ms{ret}\;\ms{inl}(x, z)}{z}{\ms{ret}\;\ms{inr}(x, z)}$
    \item Elgot structure 
    $$
      r^\dagger = \where{\ms{br}\;\ms{body}\;\invar}{\wbranch{\ms{body}}{\invar : A}
        {r ; \casestmt{\invar}{x}{\ms{ret}\;x}{y}{\ms{br}\;\ms{body}\;y}}}
    $$
  \end{itemize}
  where $\ms{ret}\;e$ denotes $\ms{br}\;\ms{ret}\;e$. Furthermore,
  \begin{enumerate}[label=(\alph*)]
    \item $e \mapsto \ms{ret}\;e$ is a full and faithful strict monoidal functor
    (taking the action on objects to be the identity)
    $\ms{Th}^\otimes_\bot(\Gamma)  
      \to \ms{Th}_\bot(\Gamma, \ms{L})(A, B)$ \label{ret-functor}.
    In particular, we have $\ms{ret}\;\delta = \delta$.
    \item Likewise $e \mapsto \letstmt{\invar}{e}{\ms{ret}\;\invar}$ is a
      faithful strict monoidal functor $\ms{Th}^\otimes(\Gamma) \to
      \ms{Th}_\bot(\Gamma, \ms{L})(A, B)$ restricting to \ref{ret-functor} on
      $\ms{Th}^\otimes_\bot(\Gamma)$
  \end{enumerate}
  % In particular, taking $\ms{Th}(\cdot, \cdot)$ as our model, we have 
  % $
  %   \lbeq{\Gamma}{r}{r'}{\ms{L}} 
  %   \iff \dnt{\haslb{\Gamma}{r}{\ms{L}}} = \dnt{\haslb{\Gamma}{r'}{\ms{L}}}
  % $
\end{theorem}

\TODO{B\"ohm-Jacopini based completeness}

\section{Concrete Models}

\subsection{Monads and Monad Transformers}

As previously stated, every strong monad over a CCC, by virtue of providing a
model of higher-order effectful programming, \emph{also} provides a model of
first-order effectful programming, i.e., SSA. In particular, the Kleisli
category of every such strong monad $\ms{T}$ is a premonoidal category and
induces a Freyd category with pure morphisms given by
\begin{equation}
  \ms{C}_{\ms{T}\bot}(A, B) = \{f;\eta_B : A \to \ms{T}B\} 
  \subseteq \ms{C}(A, \ms{T}B) = \ms{C}_{\ms{T}}(A, B)
\end{equation}
It follows that every strong Elgot monad over a CCC with all coproducts is an
\isotopessa model (since, in particular, every CCC with coproducts is
distributive). This allows us to very quickly amass a large collection of
\isotopessa models from the literature on strong Elgot monads.

Probably the simplest example of an \isotopessa model is given by the
\emph{option monad} $\ms{Option}\;A = A + \mb{1}$, with fixpoint operation
$$
  f^\dagger = \ms{some}\;b \quad \text{if} \quad \exists n, f^n\;a = \ms{some}\;(\iota_l\;b)
  \qquad
  f^\dagger = \ms{none} \quad \text{otherwise}
$$
where
$$
  f^0\;a = \ms{some}\;(\iota_r\;a) \qquad
  f^{n + 1}\;a = \ms{bind}\;(f^{n}\;a)\;[(\ms{pure};\iota_l), f] 
$$
This model allows us to interpret potentially divergent but otherwise purely
functional programs. Another very important \isotopessa model is generated by
the \emph{powerset monad} $\mc{P}(A)$, which has fixpoint operation
$$
  f^\dagger\;a = \bigcup_n\{b \mid \iota_l\;b \in f^n\;a\}
$$
We can use this monad to interpret \emph{nondeterministic} potentially divergent
functional programs, which, as we will further explore later, are a strict
superset of those which can merely diverge or terminate.

\TODO{\cite{goncharov-16-complete-elgot}, \cite{goncharov-21-uniform-elgot},
\cite{goncharov-guarded-unguarded}}

We can further expand our repertoire of \isotopessa models by considering
\emph{monad transformers}, many of which preserve Elgot-ness. For example, if
$\ms{T}$ is strong Elgot,
\begin{itemize}
  \item For all types $R$, the \emph{reader transformer}
  $\ms{ReaderT}\;R\;\ms{T}\;A = R \to \ms{T}\;A$ is strong Elgot 
  with monad operations
  ...
  and fixpoint
  ...
  \item For all monoids $W$, the \emph{writer transformer}
  $\ms{WriterT}\;W\;\ms{T}\;A = \ms{T}\;(A \times W)$ is strong Elgot 
  with monad operations
  ...
  and fixpoint
  ...
  \item For all types $S$, the \emph{state transformer}
  $\ms{StateT}\;S\;\ms{T}\;A = S \to \ms{T}(A \times S)$ is strong Elgot 
  with monad operations
  ...
  and fixpoint
  ...
\end{itemize}

One other important source of \isotopessa models is via \emph{Elgot submonads}
of monads on \ms{Set}, which we define as follows:
\begin{definition}[Elgot submonad]
  A monad $(\ms{S}, \eta', \mu')$ is a submonad of $(\ms{T}, \eta, \mu)$ if
  $\eta = \eta'$, $\forall A, \ms{S}\;A \subseteq \ms{T}\;A$, and, on the set
  $\ms{S}\;(\ms{S}\;A) \subseteq \ms{T}\;(\ms{T}\;A)$, $\mu = \mu'$. We say
  $\ms{S}$ is \emph{strong Elgot} if $\ms{T}$ is strong Elgot and, for all $f
  \in A \to \ms{S}\;(A + B)$, $f^\dagger \in A \to \ms{S}\;B$ (i.e. the fixpoint
  operation sends the Kleisli category of $\ms{S}$ to itself).
\end{definition}

\TODO{does there exist an Elgot monad which is not strong Elgot?}

As a concrete example, interpreting $\ms{some}\;A = \{a\}$ and $\ms{none} =
\varnothing$, we can view $\ms{Option}$ as an Elgot submonad of $\mc{P}$.
Similarly, 
\TODO{monad transformer lore, needs formalization...}

\TODO{frame as subcategory}

\subsection{Trace Models}

A particularly important class of \isotopessa models are what we will call
\emph{trace models}, which can be viewed as programs which either diverge or
produce a result, while also producting (potentially nondeterministic,
potentially infinite) traces of events $\epsilon \in \mc{E}$.

\TODO{naming}

\begin{definition}[(Monoidal) Stream Action]
  A \textit{stream action} $(M, I, \cdot, \Sigma)$ is a set $M$ of \emph{finite
  effects} and set $I$ of \emph{divergent effects} equipped with a binary
  function (``action'') $\cdot : M \times I \to I$ and a function $\Sigma : M^\omega \to I$
  mapping infinite streams of $M$ to an element of $I$ satisfying $\Sigma \sigma
  = \sigma_0 \cdot \Sigma_i \sigma_{i + 1}$, where $\Sigma_i \sigma_i = \Sigma
  (\lambda i. \sigma_i)$. If $M$ is a monoid and $(M, I, \cdot)$ a monoid
  action, in which case we have a \emph{monoidal} stream action
\end{definition}
The most important example of a monoidal stream action is the \emph{free}
monoidal stream action over a set $E$, called the set of \emph{events}, where:
\begin{itemize}
  \item $M = E^*$ is the free monoid over a set of ``events" $\epsilon \in E$, i.e., the
  monoid of finite lists of events
  \item $I = E^{\leq \omega}$ is the set of \textit{potentially} infinite
  streams of events $\epsilon \in E$
  \item $m \cdot i$ is defined in the obvious manner, i.e. by prepending the (finite) stream $m$ to the
  (potentially infinite) stream $i$
  \item $\Sigma\;\sigma$ is defined as the supremum $\bigsqcup_it_i$, where $t
  \leq t'$ iff $t$ is a prefix of $t'$, $t_0 = \bot$ (the empty stream), and
  $t_{i + 1} = t_i \cdot \sigma_i$
\end{itemize}
Other important examples include:
\begin{itemize}
  \item The free stream action over a set of events $E$, where $M = E$, $I =
  E^\omega$ (the set of infinite streams of events $\epsilon$), $m \cdot i$ is
  merely prepending $m$ to the stream $i$, and $\Sigma \sigma = \sigma$
  \item The terminal stream action over an arbitrary set $M$, where $I
  = \mb{1}$. This is always a monoidal stream action if $M$ is a monoid
\end{itemize}

\begin{definition}[Trace Monad Transformer]
  Given a monoidal stream action $(M, I, \cdot)$, we can define the \emph{trace
  monad transformer} over $\ms{Set}$ as follows:
  $
  \ms{TraceT}\;M\;I\;\ms{T}\;A = \ms{T}\;(A \times M + I)
  $
  with monad operations
  $$
  \eta = (\lambda a. \iota_l (a, 0)) ; \eta_{\ms{T}} \qquad
  \ms{bind}\;a\;f = \sorry
  %\ms{bind}_{\ms{T}}\;a\;[\lambda (a, m). m \cdot f a, \lambda i. \eta_{\ms{T}}(\iota_r\;i)]
  $$
  \
  \begin{itemize}
    \item \todo{\ms{TraceT}}
    \item \todo{\ms{Traces?}}
    \item \todo{\ms{Traces}}
    \item \todo{\ms{Trace}}
  \end{itemize}
\end{definition}
As a simple, concrete example of type type of model this construction lets us define, consider the
\textbf{nondeterministic printing monad}, which is simply defined as \(\ms{Print}\;A \equiv
\ms{Traces}\;\Sigma\), where \(\Sigma: (\ms{byte}^*)^\omega \to \ms{byte}^{\leq \omega}\) denotes
concatenation of bytestrings into a potentially infinite bytestream. This gives us us an \isotopessa
model supporting effectful instructions \(\ms{print}: \ms{byte}^* \to \mb{1}\) and \(\ms{nondet}:
\mb{1} \to A\) (for \(A\) nonempty), with semantics \(\dnt{\ms{print}} = \lambda b.\{\iota_0 ((),
b)\}\), \(\dnt{\ms{nondet}} = \lambda (). \{\iota_0 (a, []) \mid a \in A\}\).

We can make things a little more interesting by adding a heap to the mix, defining our monad
\(\ms{Comp} = \ms{StateT}\;\ms{Heap}\;\ms{Print}\), where \(\ms{Heap} = \nats \rightharpoonup
\nats\) is simply a partial function with finite support. The Kleisli category of this monad is also
a Freyd category and inherits an Elgot structure from that on \(\ms{Set}_{\ms{Print}}\); we
therefore have an \isotopessa model supporting the instructions \(\ms{set}: \nats \times \nats \to
\mb{1}\), \(\ms{get}: \nats \to \nats\), \(\ms{alloc}: \nats \to \nats)\), and \(\ms{free}: \nats
\to \mb{1}\). We can assign semantics to \(\ms{set}\) in the standard fashion, with \(\dnt{\ms{set}}
= \lambda (p, v)\;h. \{\iota_0((), [p \mapsto v]h, [])\}\). \(\ms{get}\) is a bit more tricky, since
it is unclear what to do when we try to access uninitialized memory: one option is simply to return
an arbitrary value, with \(\dnt{\ms{get}} = \lambda p\;h. \{\iota_0(v, h, []) \mid v = h\;p \lor p
\notin h\}\). Finally, \(\dnt{\ms{alloc}} = \lambda v\;h.\{\iota_0\;(p, h', []) \mid h' = h \sqcup p
\mapsto v\}\) simply fills a random empty heap cell with the provided value, returning a pointer to
the cell, while \(\dnt{\ms{free}} = \lambda p\;h. \{\iota_0\;((), h \setminus p, [])\}\).

As we can see, the trace monad is a very powerful tool for quickly constructing families of
\isotopessa models, at least for relatively simple side-effects. It turns out, however, that the
same techniques can be used to tackle much more complex side-effects; to demonstrate this, we will
show how to build a simple model of TSO weak memory based on that given in \citet{sparky}.

\section{TSO weak memory}

To start, we need to construct an appropriate stream action monoid to take our traces over. For
simplicity, we will consider an infinite set of named locations \(x, y, z \in \ms{Loc}\) which are
subject to concurrent modification by all threads via TSO reads, writes, and fences. We begin with
the following definitions:
\begin{definition}[Pomset] 
  A \textbf{pomset} \(\alpha\) over a set of actions \(\mc{A}\) with a distinguished null action
  "\textbf{tick}" \(\delta \in \mc{A}\) is a \textit{nonempty} partially-ordered \textbf{carrier
  set} \(P\) such that every \(p \in P\) has finitely many predecessors equipped with a mapping
  \(\alpha: P \to \mc{A}\) quotiented over the removal of \(\delta\) such that cardinality is
  preserved. A pomset is \textbf{finite} if its carrier set is. We will write unordered pomsets
  using multiset notation, e.g. \(\{a, a, b\}\), and linearly ordered pomsets using list notation,
  e.g. \([a, a, b]\).
\end{definition}
(Finite) pomsets form a monoid under sequential composition \(\alpha;\beta\), which is defined by
the function \([\alpha, \beta]: \ms{trim}(P + Q) \to \mc{A}\), where \(P + Q\) is given the
lexicographic ordering and \(\ms{trim}(R)\) removes all elements of \(R\) with infinitely many
predecessors. They also form a monoid under parallel composition, defining \(\alpha || \beta =
[\alpha, \beta]: P + Q \to \mc{A}\) where \(P + Q\) is given the standard partial ordering (with
elements of \(P\) and \(Q\) incomparable). Note in both cases the monoidal unit is \(\{\delta\}\),
since we only consider nonempty pomsets but allow the removal of finitely many ticks. Given any
partially ordered set \(N\) and a family of pomsets \(\alpha_n\) for \(n \in N\), we can define
their \textit{sum} \(\Sigma_n\alpha_n\) to be given by the function \((n, a) \mapsto \alpha_n\;a:
\ms{trim}(\Sigma_nP_n) \to \mc{A}\), where the dependent product \(\Sigma_nP_n\) is given the
lexicographic order. In particular, choosing \(N = \nats\) makes \(\Sigma:
\ms{Pom}_{\ms{fin}}^\omega \to \ms{Pom}\) into a stream action monoid w.r.t the sequential
composition monoid on finite pomsets. 

We define a \textbf{program order pomset} to be a pomset with \(\mc{A}_{\ms{PO}} = \mc{A}_w \cup
\mc{A}_r \cup \{\delta\}\), where \(\mc{A}_r\) consists of \textit{reads} of the form \(x = v\) and
\(\mc{A}_w\) consists of \textit{writes} of the form \(x := v\) for locations \(x\) and values \(v
\in \ms{Word}\). We define the \textbf{program order monad} \(\ms{PO}\;A = \ms{Traces}\;\Sigma\;A\),
where \(\Sigma\) is taken as a stream action on finite program order pomsets. This yields an
\isotopessa model with support for concurrent read and write operations \(\ms{read}_x:
\mc{I}^\varnothing_0(\mb{1}, \ms{Word})\), \(\ms{write}_x: \mc{I}^\varnothing_0(\ms{Word}, \mb{1})\)
with semantics
\(
  \dnt{\ms{read}_x} = R_x^{\ms{PO}} = \lambda (). \{(v, \{x = v\}) | v \in \ms{Word}\}
\),
\(
  \dnt{\ms{write}_x} = W_x^{\ms{PO}} =  \lambda v. \{((), \{x := v\})\}
\).
The semantics of \(\ms{read}\) in particular give a hint as to how this model works: rather than
tracking the state of the heap, we simply \textit{emit} a pomset of the events that would have be
generated by a given execution (in the case of a read, a read event \(x = v\) whenever the read
returns \(v\), and in the case of a write, the single write event \(x := v\) for a write of \(v\)),
and later post-filter to obtain a set of valid executions. By doing so, our semantics remains
compositional, allowing us to reason about each program fragment individually, while still allowing
other program fragments to perform concurrent operations affecting our potential executions. On that
note, we can define the \textit{parallel execution} of two morphisms as follows:
\begin{equation}
  \begin{aligned}
  f_0 || f_1 = \lambda (a_0, a_1). 
  & \{\iota_0 ((b_0, b_1), \alpha_0 || \alpha_1) 
    \mid \iota_0 (b_i, \alpha_i) \in f_i\;a_i\} 
  \\ & \cup \{\iota_1 (\alpha_0 || \alpha_1) 
      \mid (\iota_0 (b_0, \alpha_0) \in f_0\;a \lor \iota_0\;\alpha_0 \in f_0\;a_0) 
      \land \iota_1 \alpha_1 \in f_1\;a_1\} 
  \\ & \cup \{\iota_1 (\alpha_0 || \alpha_1) 
      \mid \iota_1\;\alpha_0 \in f_0\;a_0 
      \land \iota_0 (a_1, \alpha_1) \in f_1\;a_1\}
    : \ms{Set}_{\ms{PO}}(A \otimes A', B \otimes B')
  \end{aligned}
\end{equation}
It's tempting to try to use this to define a tensor product of morphisms to obtain a monoidal
(rather than preomonoidal) category, but unfortunately, sliding still fails: \((W_x^{\ms{PO}} ||
\ms{id}) ; (\ms{id} || W_y^{\ms{PO}})\) emits the pomset \([x := a, y := b]\), while \((\ms{id} ||
W_y^{\ms{PO}}) ; (W_x^{\ms{PO}} || \ms{id})\) emits the pomset \([y := b, x := a]\). 
% If we did want this behaviour, we'd need to have a significantly more
% sophisticated model of composition which effectively takes nontermination into
% account, which we will leave to future work.

To graduate from sequential consistency to a genuine, if maximally simple, weak memory model, we
introduce \textit{load buffering} of write actions. We will implement TSO ordering by buffering all
our writes, in which case they are only visible to the local thread. On the other hand, read events
will first attempt to read from the buffer, and, if there is no corresponding write in the buffer,
will read an arbitrary value, in both cases pushing an event to the global pomset. At any point, we
may choose to \textit{flush} some of the buffered writes. We introduce the set \(\mc{A}_b =
\{(\bufloc{x} := v)\}\) of \textit{buffer write actions}, where an action \(\bufloc{x} := v\) by a
thread denotes adding a write \(x := v\) to the thread's write buffer. We may then define the set of
TSO actions \(\mc{A}_{\ms{TSO}} = \mc{A}_{\ms{PO}} \cup \mc{A}_b\); a pomset over this set is called
a \textbf{TSO pomset}. A buffer will be defined to be a list of write actions \(\ms{Buf} =
\mc{A}_b^*\), which we will interpret as linear pomsets over \(\mc{A}_{\ms{TSO}}\) ordered by index
(with the empty list corresponding to \(\{\delta\}\)). In particular, we define the monad \(\ms{TSO}
= \ms{StateT}\;\ms{Buf}\;(\ms{Trace}\;\Sigma)\), where \(\Sigma\) is taken as a the stream action of
finite TSO pomsets on TSO pomsets. We can view \(\ms{PO}\) as a submonad of this monad.

Given a buffer \(\ms{Buf}\), we can define the result of reads \([\cdot]_x: \ms{Buf} \to \ms{Word}
\sqcup \{\bot\}\) from the buffer by induction to be:
\(
  (L;\{\bufloc{x} := v\})[x] = v,
\),
\(
  (L;\{\bufloc{y} := v\})[x] = L[x]
\),
\(
  [][x] = \bot
\).
% Note that writes at the \textit{end} of the buffer are prioritized, since
% later writes overwrite earlier ones! 
The semantics of reads and writes can then be given by
\begin{equation}
  \begin{aligned}
  \dnt{\ms{read}_x} = R_x^{\ms{TSO}} 
    &= \ms{pflush};(\lambda ()\;L. \{(v, L, \{x = v\}) \mid L[x] = v \lor L[x] = \bot\});\ms{pflush} 
  \\
  \dnt{\ms{write}_x} = W_x^{\ms{TSO}}
    &= \ms{pflush};(\lambda v\;L. \{(v, (L;\{\bufloc{x} := v\}), \{x := v\})\});\ms{pflush}
  \end{aligned}
\end{equation}
where buffer flushing is implemented via the morphism 
$$
  \ms{pflush}_A = \lambda a\;L. \{(a, R, \alpha) | L = \alpha;R\}
  : \ms{Set}_{\ms{TSO}}(A, A)
$$
(called \(\ms{split}\) in \cite{sparky}). To be able to perform synchronization, we will also need
to introduce a \(\ms{fence}: \mc{I}^\varnothing_0(\mb{1}, \mb{1})\) instruction, which simply causes
all actions before the fence to be observed before any actions after the fence. For \(\ms{TSO}\),
implementing this is as simple as flushing the buffer, i.e., we define
$$
  \dnt{\ms{fence}} = \lambda ()\;L. \{((), [], L;\{\delta\})\}
$$
We can now define the parallel composition of morphisms in a "fork-join" style as follows: we first
flush the buffer completely (i.e., taking it and sticking it at the beginning of our pomset), then
execute \(f\) and \(g\) in parallel with separate buffers, \textit{filtering out executions which
completely flush the buffer}. Since both threads end up with an empty buffer, the resulting joined
buffer is also empty, giving us the following definition:
\begin{equation}
  \begin{aligned}
    f_0 || f_1 = \lambda (a_0, a_1)\;L. 
    & \{\iota_0 ((b_0, b_1), [], L;(\alpha_0 || \alpha_1)) 
      \mid \iota_0 (b_i, [], \alpha_i) \in f_i\;a_i\;[]\} 
    \\ & \cup \{\iota_1 (\alpha_0 || \alpha_1) 
        \mid (\iota_0 (b_0, [], \alpha_0) \in f_0\;a \lor \iota_0\;\alpha_0 \in f_0\;a_0\;[]) 
        \land \iota_1 \alpha_1 \in f_1\;a_1\;[]\} 
    \\ & \cup \{\iota_1 (\alpha_0 || \alpha_1) 
        \mid \iota_1\;\alpha_0 \in f_0\;a_0\;[] 
        \land \iota_0 (a_1, [], \alpha_1) \in f_1\;a_1\;[]\}
    \end{aligned}
\end{equation}

\TODO{this category has ``too many'' morphisms: \ms{pflush}-sandwich subcategory; Elgot lore?}

\section{Discussion and Related Work}

\TODO{Maybe cite how we're doing \citet{liang-95-interpreters} here}

\TODO{Release-acquire lore; event structure lore}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\clearpage 

\appendix

\section{Bhm-Jacopini Theorem}

\TODO{this...}

\section{Normalization}

\TODO{to Expr...}

\TODO{to BBRegion...}

\TODO{to TRegion ...}

\TODO{to ContRegion ...}

% \begin{figure}
%   \begin{gather*}
%     \prftree[r]{\rle{let$_1$-case}}
%       {\hasty{\Gamma}{\epsilon}{a}{A + B}}
%       {\hasty{\Gamma, \bhyp{x}{A + B}}{\epsilon}{c}{C}}
%       {
%         \prfStackPremises
%         {\hasty{\Gamma, \bhyp{x}{A + B}, \bhyp{y}{C}, \bhyp{z}{A}}{\epsilon}{d}{D}}
%         {\hasty{\Gamma, \bhyp{x}{A + B}, \bhyp{y}{C}, \bhyp{z'}{B}}{\epsilon}{d'}{D}}
%       }
%       {
%         \prfStackPremises
%         {\Gamma \vdash_\epsilon \letexpr{x}{a}{\letexpr{y}{c}{\caseexpr{x}{z}{d}{z'}{d'}}}}
%         {\hspace{6em} \teqv 
%                  \letexpr{x}{a}{\caseexpr{x}{z}{\letexpr{y}{c}{d}}{z'}{\letexpr{y}{c}{d'}}} 
%         : D}
%       }
%     \\
%     \prftree[r]{\rle{let$_2$-case}}
%       {\hasty{\Gamma}{\epsilon}{a}{A + B}}
%       {\hasty{\Gamma, \bhyp{x}{A + B}}{\epsilon}{c}{C \otimes D}}
%       {
%         \prfStackPremises
%         {\hasty{\Gamma, \bhyp{x}{A + B}, \bhyp{y}{C}, \bhyp{z}{D}, \bhyp{w}{A}}{\epsilon}{e}{E}}
%         {\hasty{\Gamma, \bhyp{x}{A + B}, \bhyp{y}{C}, \bhyp{z}{D}, \bhyp{w'}{B}}{\epsilon}{e'}{E}}
%       }
%       {
%         \prfStackPremises
%         {\Gamma \vdash_\epsilon \letexpr{x}{a}{\letexpr{(y, z)}{c}{\caseexpr{x}{w}{e}{w'}{e'}}}}
%         {\hspace{5em} \teqv \letexpr{x}{a}
%           {\caseexpr{x}
%             {w}{\letexpr{(y, z)}{c}{e}}
%             {w'}{\letexpr{(y, z)}{c}{e'}}} 
%         : E}
%       }
%     \\
%     \prftree[r]{\rle{case-case}}
%       {\hasty{\Gamma}{\epsilon}{a}{A_1 + A_2}}
%       {\hasty{\Gamma, \bhyp{x}{A + B}}{\epsilon}{b}{B_1 + B_2}}
%       {
%         \forall i j.
%         \hasty{\Gamma, \bhyp{x}{A_1 + A_2}, \bhyp{y_i}{B_i}, \bhyp{z_j}{A_j}}{\epsilon}
%               {c_{ij}}{C}
%       }
%       {
%         \prfStackPremises
%         {\Gamma \vdash_\epsilon 
%           \ms{let}\;x = a;
%           \ms{case}\;b\;\{\ms{inl}\;y_1 \lto \caseexpr{x}{z_1}{e_{11}}{z_2}{e_{12}}
%         }
%         {
%           \hspace{10em} \ms{inr}\;y_2 \lto \caseexpr{x}{z_1}{e_{21}}{z_2}{e_{22}} \}
%         }
%         {\hspace{1.3em} \teqv
%           \ms{let}\;x = a;
%           \ms{case}\;x\;\{\ms{inl}\;z_1 \lto \caseexpr{b}{y_1}{e_{11}}{y_2}{e_{21}}
%         }
%         {
%           \hspace{10em} \ms{inr}\;z_2 \lto \caseexpr{b}{y_1}{e_{12}}{y_2}{e_{22}} \}
%         }
%       }
%     \\
%     \prftree[r]{\rle{op-case}}
%       {\hasty{\Gamma}{\epsilon}{e}{A + B}}
%       {\isop{f}{C}{D}{\epsilon}}
%       {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{C}}
%       {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{c'}{C}}
%       {\tmeq{\Gamma}{\epsilon}{\caseexpr{e}{x}{f\;c}{y}{f\;c'}}{f\;\caseexpr{e}{x}{c}{y}{c'}}{D}}
%     \\
%     \prftree[r]{\rle{inl-case}}
%       {\hasty{\Gamma}{\epsilon}{e}{A + B}}
%       {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{C}}
%       {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{c'}{C}}
%       {\tmeq{\Gamma}{\epsilon}
%         {\caseexpr{e}{x}{\linl{c}}{y}{\linl{c'}}}
%         {\linl{\caseexpr{e}{x}{c}{y}{c'}}}
%         {C + D}}
%     \\
%     \prftree[r]{\rle{inr-case}}
%       {\hasty{\Gamma}{\epsilon}{e}{A + B}}
%       {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{d}{D}}
%       {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{d'}{D}}
%       {\tmeq{\Gamma}{\epsilon}
%         {\caseexpr{e}{x}{\linr{d}}{y}{\linr{d'}}}
%         {\linr{\caseexpr{e}{x}{d}{y}{d'}}}
%         {C + D}}
%     \\
%     \prftree[r]{\rle{abort-case}}
%     {\hasty{\Gamma}{\epsilon}{e}{A + B}}
%     {\hasty{\Gamma, \bhyp{x}{A}}{\epsilon}{c}{\mb{0}}}
%     {\hasty{\Gamma, \bhyp{y}{B}}{\epsilon}{c'}{\mb{0}}}
%     {
%       \prfStackPremises
%       {\Gamma \vdash_\epsilon \caseexpr{e}{x}{\labort{c}}{y}{\labort{c'}}}
%       {\teqv \labort{\caseexpr{e}{x}{c}{y}{c'}} : C}
%     }
%     \\
%     \prftree[r]{\rle{pair-case}}
%       {\hasty{\Gamma}{\epsilon}{e}{A_1 + A_2}}
%       {\forall i, \hasty{\Gamma, \bhyp{x_i}{A_i}}{\epsilon}{b_{ij}}{B_j}}
%       {
%         \prfStackPremises
%         {\Gamma \vdash_\epsilon \caseexpr{e}{x}{(b_{11}, b_{12})}{y}{(b_{21}, b_{22})}}
%         {\teqv (\caseexpr{e}{x}{b_{11}}{y}{b_{21}}, \caseexpr{e}{x}{b_{12}}{y}{b_{22}}) 
%         : B_1 \otimes B_2}
%       }
%     \\
%     \prftree[r]{\rle{case$_0$}}
%       {\hasty{\Gamma}{\epsilon}{e}{A_1 + A_2}}
%       {\hasty{\Gamma}{\epsilon}{a}{A}}
%       {\tmeq{\Gamma}{\epsilon}{\caseexpr{e}{x}{a}{y}{a}}{a}{A}}
%   \end{gather*}
%   \Description{}
%   \caption{Derivable rules rules for \isotopessa \ms{case} expressions}
% \end{figure}

\end{document}
\endinput
